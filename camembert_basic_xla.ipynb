{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "camembert_basic_xla.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Bmeym7tVqfX0"
      ],
      "authorship_tag": "ABX9TyPzky9hBldfkxtFwkXMNchO"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f079e84e3c154d009e4e2afdafd63dd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_949d10035b9242df8b4ce64f3964677d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bfc3bb79cb1b4b49917f575e5fedf298",
              "IPY_MODEL_4e2d2972031040f5b834708fd90cd2b2"
            ]
          }
        },
        "949d10035b9242df8b4ce64f3964677d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bfc3bb79cb1b4b49917f575e5fedf298": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cab60f3785d94ce58250a42964db3805",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 810912,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 810912,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_da9ce77a6f0b4030b2d66d704a031a4b"
          }
        },
        "4e2d2972031040f5b834708fd90cd2b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6e58bc49b86e4713b11d522ee6a54116",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 811k/811k [00:00&lt;00:00, 1.35MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ccb15794adc64ef8b2dce0bc7f5dcdae"
          }
        },
        "cab60f3785d94ce58250a42964db3805": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "da9ce77a6f0b4030b2d66d704a031a4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6e58bc49b86e4713b11d522ee6a54116": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ccb15794adc64ef8b2dce0bc7f5dcdae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4000015b16894c089868db9ae2592078": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ae2c2bedd65445e8befc4a92497bd6d0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ef4ddd6ecf46489892e2832ee320dcdd",
              "IPY_MODEL_1c27f264207043bf8e7f8a878e67a7a4"
            ]
          }
        },
        "ae2c2bedd65445e8befc4a92497bd6d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ef4ddd6ecf46489892e2832ee320dcdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bd9bcba910404635aa045bee208c7b76",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4f3701e26c9347ce90a6746f94fd61a7"
          }
        },
        "1c27f264207043bf8e7f8a878e67a7a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_263d28136daa4401bc14058b2cf3fc46",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 508/508 [00:26&lt;00:00, 18.8B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f4a7e73b2ff34ae697355943fb0323f9"
          }
        },
        "bd9bcba910404635aa045bee208c7b76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4f3701e26c9347ce90a6746f94fd61a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "263d28136daa4401bc14058b2cf3fc46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f4a7e73b2ff34ae697355943fb0323f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "87ef0119da6445e0898f7c4e633b2f51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_019bb7e99ff3460cb7b2df8c2bf5d9d6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e592c1e0d5af4a14936d26c44e3f3926",
              "IPY_MODEL_f57dc7e3486246c5b35bb68ca65e4267"
            ]
          }
        },
        "019bb7e99ff3460cb7b2df8c2bf5d9d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e592c1e0d5af4a14936d26c44e3f3926": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3fd079c8e6854604ab345bab3fbc797f",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 59,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 59,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a4028ed53a7c41509b6182b1aba4b6b9"
          }
        },
        "f57dc7e3486246c5b35bb68ca65e4267": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1c54e43677b04db68c7434b6634d0e5e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 59/59 [00:14&lt;00:00,  4.18it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f3881c4f7f2f4bbcaaa7986bb39d495a"
          }
        },
        "3fd079c8e6854604ab345bab3fbc797f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a4028ed53a7c41509b6182b1aba4b6b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1c54e43677b04db68c7434b6634d0e5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f3881c4f7f2f4bbcaaa7986bb39d495a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVpqAMUEOeZL",
        "colab_type": "text"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GniexJjK6gA8",
        "colab_type": "text"
      },
      "source": [
        "Prepping things up for TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ga69MZG2OgYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5NpJHrwOh1c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 978
        },
        "outputId": "c9a2be9b-a08a-448b-9e95-6e2f06ed5713"
      },
      "source": [
        "VERSION = \"nightly\"  #@param [\"1.5\" , \"20200516\", \"nightly\"]\n",
        "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "!python pytorch-xla-env-setup.py --version $VERSION"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  4264  100  4264    0     0  59222      0 --:--:-- --:--:-- --:--:-- 59222\n",
            "Updating TPU and VM. This may take around 2 minutes.\n",
            "Updating TPU runtime to pytorch-nightly ...\n",
            "Uninstalling torch-1.5.1+cu101:\n",
            "Done updating TPU runtime: <Response [200]>\n",
            "  Successfully uninstalled torch-1.5.1+cu101\n",
            "Uninstalling torchvision-0.6.1+cu101:\n",
            "  Successfully uninstalled torchvision-0.6.1+cu101\n",
            "Copying gs://tpu-pytorch/wheels/torch-nightly-cp36-cp36m-linux_x86_64.whl...\n",
            "- [1 files][106.7 MiB/106.7 MiB]                                                \n",
            "Operation completed over 1 objects/106.7 MiB.                                    \n",
            "Copying gs://tpu-pytorch/wheels/torch_xla-nightly-cp36-cp36m-linux_x86_64.whl...\n",
            "- [1 files][122.0 MiB/122.0 MiB]                                                \n",
            "Operation completed over 1 objects/122.0 MiB.                                    \n",
            "Copying gs://tpu-pytorch/wheels/torchvision-nightly-cp36-cp36m-linux_x86_64.whl...\n",
            "/ [1 files][  1.7 MiB/  1.7 MiB]                                                \n",
            "Operation completed over 1 objects/1.7 MiB.                                      \n",
            "Processing ./torch-nightly-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==nightly) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==nightly) (1.18.5)\n",
            "\u001b[31mERROR: fastai 1.0.61 requires torchvision, which is not installed.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "Successfully installed torch-1.6.0a0+ab8a99b\n",
            "Processing ./torch_xla-nightly-cp36-cp36m-linux_x86_64.whl\n",
            "Installing collected packages: torch-xla\n",
            "Successfully installed torch-xla-1.6+ce76ba3\n",
            "Processing ./torchvision-nightly-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly) (1.18.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly) (1.6.0a0+ab8a99b)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly) (7.0.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchvision==nightly) (0.16.0)\n",
            "Installing collected packages: torchvision\n",
            "Successfully installed torchvision-0.7.0a0+cd2b7f0\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  libomp5\n",
            "0 upgraded, 1 newly installed, 0 to remove and 59 not upgraded.\n",
            "Need to get 234 kB of archives.\n",
            "After this operation, 774 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\n",
            "Fetched 234 kB in 1s (363 kB/s)\n",
            "Selecting previously unselected package libomp5:amd64.\n",
            "(Reading database ... 144328 files and directories currently installed.)\n",
            "Preparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\n",
            "Unpacking libomp5:amd64 (5.0.1-1) ...\n",
            "Setting up libomp5:amd64 (5.0.1-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0s29BtVjVana",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "\n",
        "def create_path(path):\n",
        "    if not os.path.isdir(path):\n",
        "        path.mkdir(parents=True, exist_ok=True)\n",
        "    return path\n",
        "\n",
        "colab_path = Path('/content')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjp17fM_VU-R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "create_path(colab_path/'dataset');\n",
        "create_path(colab_path/'models');\n",
        "\n",
        "!git clone --quiet 'https://github.com/tezike/download_google_drive.git'\n",
        "os.chdir('download_google_drive')\n",
        "!python download_gdrive.py '10rH0nAxa7mWS289xIyRP-mOOowqiIolL' '../dataset/temp.tgz'\n",
        "shutil.rmtree('../download_google_drive')\n",
        "os.chdir('..')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQNK70EuxrRr",
        "colab_type": "text"
      },
      "source": [
        "## Colab_setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdKS3nNT0IKp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "0679fb7e-f0b3-432f-e85b-7ebb25e8aeb4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "root_dir = Path('/content/drive/My Drive')\n",
        "base_path = create_path(root_dir/'Rakuten')\n",
        "base_path"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/content/drive/My Drive/Rakuten')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5N3Yehzed8gZ",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-5fNbZ9gdbT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "f9a1c871-0e12-44bc-bd5f-6e9099a5e251"
      },
      "source": [
        "!pip install transformers -q"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 675kB 3.4MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 15.4MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.8MB 23.4MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 33.6MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwVPUKqdd_UA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import transformers\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "from tqdm import notebook\n",
        "from pathlib import Path\n",
        "\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCv3RE7Q6niW",
        "colab_type": "text"
      },
      "source": [
        "prepping things up for TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1t9yDuRfOBom",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm #handles most of the basic tasks\n",
        "import torch_xla.debug.metrics as met\n",
        "import torch_xla.distributed.parallel_loader as pl #handles dataloading on multiple processes\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YehI1cgeeL1r",
        "colab_type": "text"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_-dDMrQeOjK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168,
          "referenced_widgets": [
            "f079e84e3c154d009e4e2afdafd63dd1",
            "949d10035b9242df8b4ce64f3964677d",
            "bfc3bb79cb1b4b49917f575e5fedf298",
            "4e2d2972031040f5b834708fd90cd2b2",
            "cab60f3785d94ce58250a42964db3805",
            "da9ce77a6f0b4030b2d66d704a031a4b",
            "6e58bc49b86e4713b11d522ee6a54116",
            "ccb15794adc64ef8b2dce0bc7f5dcdae",
            "4000015b16894c089868db9ae2592078",
            "ae2c2bedd65445e8befc4a92497bd6d0",
            "ef4ddd6ecf46489892e2832ee320dcdd",
            "1c27f264207043bf8e7f8a878e67a7a4",
            "bd9bcba910404635aa045bee208c7b76",
            "4f3701e26c9347ce90a6746f94fd61a7",
            "263d28136daa4401bc14058b2cf3fc46",
            "f4a7e73b2ff34ae697355943fb0323f9"
          ]
        },
        "outputId": "e20eb4f7-afd5-44bf-90a0-66ba064c512d"
      },
      "source": [
        "class Config():\n",
        "    def __init__(self):\n",
        "        self.MODEL_NAME = 'camembert-base'\n",
        "        # self.LM_MODEL = transformers.CambertForMaskedLM.from_pretrained(self.MODEL_NAME)\n",
        "        self.CLAS_MODEL = transformers.CamembertModel #.from_pretrained(MODEL_NAME)\n",
        "        self.TOKENIZER = transformers.CamembertTokenizer.from_pretrained(\n",
        "                    pretrained_model_name_or_path=self.MODEL_NAME,\n",
        "                    do_lower_case=True,\n",
        "                    )\n",
        "        self.MODEL_CONFIG = transformers.CamembertConfig.from_pretrained(self.MODEL_NAME)\n",
        "        self.COLAB_PATH = Path('/content')\n",
        "        self.BASE_PATH = base_path\n",
        "        self.DATA_PATH = create_path(base_path/'dataset')\n",
        "        self.MODEL_PATH = create_path(base_path/'models')\n",
        "        self.TEST_FILE = self.COLAB_PATH/'SIGIR-2020-EComDC-release/data/x_test_task1_phase1.tsv'\n",
        "        self.MAX_SEQ_LEN = 256\n",
        "        self.DEVICE = torch.device(f\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.TRAIN_BATCH_SIZE = 32\n",
        "        self.VALID_BATCH_SIZE = 16\n",
        "        self.NUM_EPOCHS = \n",
        "\n",
        "config = Config()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f079e84e3c154d009e4e2afdafd63dd1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=810912.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils.py:831: FutureWarning: Parameter max_len is deprecated and will be removed in a future release. Use model_max_length instead.\n",
            "  category=FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4000015b16894c089868db9ae2592078",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=508.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqPwYfdFde8g",
        "colab_type": "text"
      },
      "source": [
        "## DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztg_Iy6hV1VC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, text, label):\n",
        "        self.text, self.label = text, label\n",
        "        self.tokenizer = config.TOKENIZER\n",
        "        self.max_len = config.MAX_SEQ_LEN\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.label)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        # sanity check\n",
        "        text = ' '.join(self.text[i].split())\n",
        "\n",
        "        # tokenize using Huggingface tokenizers\n",
        "        out = self.tokenizer.encode_plus(text, None, \n",
        "                                   add_special_tokens=True, \n",
        "                                   max_length = self.max_len)\n",
        "        \n",
        "        ids = out['input_ids']\n",
        "        mask = out['attention_mask']\n",
        "        \n",
        "        padding_length = self.max_len - len(ids)\n",
        "        ids = ids + ([0] * padding_length)\n",
        "        mask = mask + ([0] * padding_length)\n",
        "\n",
        "        return {\n",
        "            'ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'targets': torch.tensor(self.label[i], dtype=torch.float)\n",
        "        }"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCZqMIycty9o",
        "colab_type": "text"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQexDRqat0TO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AverageMeter():\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bmeym7tVqfX0",
        "colab_type": "text"
      },
      "source": [
        "## Engine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEtMYo_AqiCJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_fn(y_pred, y_true):\n",
        "        return nn.CrossEntropyLoss()(y_pred, y_true[..., None])\n",
        "\n",
        "def train(train_dl, model, optimizer, device, scheduler=None):\n",
        "    model.train()\n",
        "\n",
        "    loss_all = AverageMeter()\n",
        "    all_losses = []\n",
        "    losses = 0.\n",
        "    p_bar = notebook.tqdm(train_dl, total=len(train_dl))\n",
        "    for i, batch in enumerate(p_bar):\n",
        "        ids = batch['ids']\n",
        "        mask = batch['mask']\n",
        "        targets = batch['targets']\n",
        "\n",
        "        ids = ids.to(device, dtype=torch.long)\n",
        "        mask = mask.to(device, dtype=torch.long)\n",
        "        targets = targets.to(device, dtype=torch.float)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        model.zero_grad()\n",
        "\n",
        "        out = model(ids, mask)\n",
        "\n",
        "        loss = loss_fn(out, targets)\n",
        "        all_losses.append(loss.item())\n",
        "        losses += loss.cpu().detach().item()\n",
        "        loss.backward()\n",
        "        xm.optimizer_step(optimizer)\n",
        "        scheduler.step()  #supposed to be after epoch\n",
        "\n",
        "        # calc metrics\n",
        "        \n",
        "        break\n",
        "    # accuracy_all.update(np.mean(accuracys), ids.size(0))\n",
        "    # auc_all.update(np.mean(aucs), ids.size(0))\n",
        "    loss_all.update(loss.item(), ids.size(0))\n",
        "    p_bar.set_postfix(loss=loss_all.avg)\n",
        "\n",
        "def evaluate(valid_dl, model, device):\n",
        "    model.eval()\n",
        "    all_losses = []\n",
        "    fin_targs = []\n",
        "    fin_outs = []\n",
        "    losses = 0.\n",
        "    loss_all = AverageMeter()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        p_bar = notebook.tqdm(valid_dl, total=len(valid_dl))\n",
        "        for i, batch in enumerate(p_bar):\n",
        "            ids = batch['ids']\n",
        "            mask = batch['mask']\n",
        "            targets = batch['targets']\n",
        "\n",
        "            ids = ids.to(device, dtype=torch.long)\n",
        "            mask = mask.to(device, dtype=torch.long)\n",
        "            targets = targets.to(device, dtype=torch.float)\n",
        "\n",
        "            # model.zero_grad()\n",
        "            out = model(ids, mask)\n",
        "            loss = loss_fn(out, targets)\n",
        "\n",
        "            all_losses.append(loss.item())\n",
        "            targ_np = targets.cpu().detach().numpy().tolist()\n",
        "\n",
        "            soft_out = F.softmax(out.cpu().detach(), dim=-1)\n",
        "            out_np = soft_out.argmax(-1).numpy().tolist()\n",
        "\n",
        "            fin_targs.extend(targ_np)\n",
        "            fin_outs.extend(out_np)\n",
        "            break\n",
        "\n",
        "        loss_all.update(loss.item(), ids.size(0))\n",
        "        p_bar.set_postfix(loss=loss_all.avg)\n",
        "    return fin_targs, fin_outs, losses"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0vs7hY5lScN",
        "colab_type": "text"
      },
      "source": [
        "## MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72Rwh_l2oiB8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ClasModel(nn.Module):\n",
        "    def __init__(self, pretrained=True, num_classes=27):\n",
        "        super(ClasModel, self).__init__()\n",
        "        if pretrained:\n",
        "            self.model = config.CLAS_MODEL.from_pretrained(config.MODEL_NAME, config=config.MODEL_CONFIG)\n",
        "        else: \n",
        "            self.model = config.CLAS_MODEL(config.MODEL_CONFIG)\n",
        "                  \n",
        "        self.drop = nn.Dropout(0.4)\n",
        "\n",
        "        self.lin = nn.Linear(768*2, num_classes)\n",
        "    \n",
        "    def forward(self, ids, mask):\n",
        "\n",
        "        h_0, _ = self.model(ids, attention_mask=mask)\n",
        "        \n",
        "        mean_pool = torch.mean(h_0, 1)\n",
        "\n",
        "        max_pool = torch.max(h_0, 1)[0]\n",
        "\n",
        "        out = torch.cat([mean_pool, max_pool], 1)\n",
        "\n",
        "        out = self.lin(self.drop(out))\n",
        "\n",
        "        return out\n",
        "\n",
        "    # def load_lm_encoder(self,clas_model, lm_path=None):\n",
        "    #     clas_model_dict = clas_model.state_dict()\n",
        "    #     if lm_path is not None:\n",
        "    #         lm_model_dict = torch.load(lm_path).model.state_dict()\n",
        "    #         needed_dict = {k[6:]:v for k, v in lm_model_dict.items() if str(k)[6:] in clas_model_dict.keys()}\n",
        "    #         clas_model_dict.update(needed_dict)\n",
        "    #     clas_model.load_state_dict(clas_model_dict)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbP26vepa2Uv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "913ZWgCJaePS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mS1GRp6pxmH5",
        "colab_type": "text"
      },
      "source": [
        "## Prep data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWMSkVxhTFF8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -xzf $colab_path/'dataset/temp.tgz'"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7j6aWiRxper",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "a08d2228-2fa5-4a28-d4b3-760c475bdc5c"
      },
      "source": [
        "df_all = pd.read_csv(config.BASE_PATH/'dataset/df_all.csv'); \n",
        "df_all.fillna(' ', inplace=True)\n",
        "df_all.sample(1)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Description</th>\n",
              "      <th>Image_id</th>\n",
              "      <th>Product_id</th>\n",
              "      <th>Prdtypecode</th>\n",
              "      <th>Prdlbl</th>\n",
              "      <th>image_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2152</th>\n",
              "      <td>Lot 4 Livres Partitions Collection \"A Tempo\" (...</td>\n",
              "      <td></td>\n",
              "      <td>1253468564</td>\n",
              "      <td>3856816679</td>\n",
              "      <td>2403</td>\n",
              "      <td>2403</td>\n",
              "      <td>/content/SIGIR-2020-EComDC-release/image/image...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Title  ...                                         image_path\n",
              "2152  Lot 4 Livres Partitions Collection \"A Tempo\" (...  ...  /content/SIGIR-2020-EComDC-release/image/image...\n",
              "\n",
              "[1 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcQb5lhhZ5SZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "154ca216-42d9-4254-eed2-1699edab907f"
      },
      "source": [
        "le = LabelEncoder()\n",
        "le.fit(df_all.Prdlbl)\n",
        "le.classes_"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  10,   40,   50,   60, 1140, 1160, 1180, 1280, 1281, 1300, 1301,\n",
              "       1302, 1320, 1560, 1920, 1940, 2060, 2220, 2280, 2403, 2462, 2522,\n",
              "       2582, 2583, 2585, 2705, 2905])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3AYX8xQaL6o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_all.Prdlbl = le.transform(df_all.Prdlbl)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQphZQTKqNe7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b60686b0-2d2e-40d9-f749-bd1befa48c27"
      },
      "source": [
        "train_df, valid_df = train_test_split(df_all, test_size=0.2, shuffle=True, stratify=df_all.Prdlbl.values)\n",
        "train_df.reset_index(drop=True, inplace=True), valid_df.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNZuUsRAqFC5",
        "colab_type": "text"
      },
      "source": [
        "##Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCBYR452tqJZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = ClasModel(pretrained=True)\n",
        "def world_func():\n",
        "    xtra_config = config.MODEL_CONFIG\n",
        "    device = xm.xla_device()\n",
        "\n",
        "    global model\n",
        "    # print('before model on device')\n",
        "    model.to(device)\n",
        "    # print('after model on device')\n",
        "\n",
        "    def loss_fn(y_pred, y_true):\n",
        "        # print(y_pred)\n",
        "        # print(y_true)\n",
        "        return nn.CrossEntropyLoss()(y_pred, y_true)\n",
        "\n",
        "    def train(train_dl, model, optimizer, device, scheduler=None):\n",
        "        model.train()\n",
        "        # accuracy_all = AverageMeter()\n",
        "        # auc_all = AverageMeter()\n",
        "        loss_all = AverageMeter()\n",
        "        all_losses = []\n",
        "        losses = 0.\n",
        "        # p_bar = notebook.tqdm(train_dl, total=len(train_dl))\n",
        "        for i, batch in enumerate(train_dl):\n",
        "            ids = batch['ids']\n",
        "            mask = batch['mask']\n",
        "            targets = batch['targets']\n",
        "\n",
        "            ids = ids.to(device, dtype=torch.long)\n",
        "            mask = mask.to(device, dtype=torch.long)\n",
        "            targets = targets.to(device, dtype=torch.float)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            model.zero_grad()\n",
        "\n",
        "            # print('before model in train')\n",
        "            out = model(ids, mask)\n",
        "\n",
        "            # print('after model in train')\n",
        "\n",
        "            loss = loss_fn(out, targets)\n",
        "            all_losses.append(loss.item())\n",
        "            losses += loss.cpu().detach().item()\n",
        "            # print('after loss')\n",
        "\n",
        "            # if i % 100 == 0: xm.master_print(f'index: {i}, loss: {loss}')\n",
        "\n",
        "            loss.backward()\n",
        "            xm.optimizer_step(optimizer)\n",
        "\n",
        "            if scheduler is not None:\n",
        "                scheduler.step()  #supposed to be after epoch\n",
        "            \n",
        "            # print('after batch')\n",
        "\n",
        "            # calc metrics\n",
        "            \n",
        "            # break\n",
        "        # accuracy_all.update(np.mean(accuracys), ids.size(0))\n",
        "        # auc_all.update(np.mean(aucs), ids.size(0))\n",
        "        loss_all.update(loss.item(), ids.size(0))\n",
        "        # p_bar.set_postfix(loss=loss_all.avg)\n",
        "\n",
        "    def evaluate(valid_dl, model, device):\n",
        "        model.eval()\n",
        "        all_losses = []\n",
        "        fin_targs = []\n",
        "        fin_outs = []\n",
        "        losses = 0.\n",
        "        loss_all = AverageMeter()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # p_bar = notebook.tqdm(valid_dl, total=len(valid_dl))\n",
        "            for i, batch in enumerate(valid_dl):\n",
        "                ids = batch['ids']\n",
        "                mask = batch['mask']\n",
        "                targets = batch['targets']\n",
        "\n",
        "                ids = ids.to(device, dtype=torch.long)\n",
        "                mask = mask.to(device, dtype=torch.long)\n",
        "                targets = targets.to(device, dtype=torch.float)\n",
        "\n",
        "                # model.zero_grad()\n",
        "                out = model(ids, mask)\n",
        "                loss = loss_fn(out, targets)\n",
        "\n",
        "                all_losses.append(loss.item())\n",
        "                targ_np = targets.cpu().detach().numpy().tolist()\n",
        "\n",
        "                soft_out = nn.Softmax(dim=1)(out.cpu().detach())\n",
        "                out_np = soft_out.argmax(-1).numpy().tolist()\n",
        "\n",
        "                fin_targs.extend(targ_np)\n",
        "                fin_outs.extend(out_np)\n",
        "                # break\n",
        "\n",
        "            loss_all.update(loss.item(), ids.size(0))\n",
        "            # p_bar.set_postfix(loss=loss_all.avg)\n",
        "        return fin_targs, fin_outs, losses\n",
        "\n",
        "\n",
        "    train_ds = BertDataset((train_df.Title + 'xxfld' + train_df.Description).values, train_df.Prdlbl.values)\n",
        "    valid_ds = BertDataset((valid_df.Title + 'xxfld' + valid_df.Description).values, valid_df.Prdlbl.values)\n",
        "\n",
        "    ###########change happens here#####################\n",
        "    train_sampler = torch.utils.data.distributed.DistributedSampler(train_ds, \n",
        "                                                                    num_replicas=xm.xrt_world_size(),\n",
        "                                                                    rank=xm.get_ordinal(),\n",
        "                                                                    shuffle=True)\n",
        "    ###################################################\n",
        "\n",
        "    train_dl = torch.utils.data.DataLoader(train_ds, batch_size=config.TRAIN_BATCH_SIZE, \n",
        "                                        drop_last=True, num_workers=4, \n",
        "                                        sampler=train_sampler)\n",
        "\n",
        "    ###########change happens here#####################\n",
        "    valid_sampler = torch.utils.data.distributed.DistributedSampler(valid_ds, \n",
        "                                                                    num_replicas=xm.xrt_world_size(),\n",
        "                                                                    rank=xm.get_ordinal(),\n",
        "                                                                    shuffle=False)\n",
        "    ###################################################\n",
        "\n",
        "    valid_dl = torch.utils.data.DataLoader(valid_ds, batch_size=config.VALID_BATCH_SIZE, \n",
        "                                        drop_last=False, num_workers=4,\n",
        "                                        sampler=valid_sampler)\n",
        "\n",
        "\n",
        "    ############change happens here################\n",
        "    lr = 1e-05 * xm.xrt_world_size()\n",
        "    #############################\n",
        "\n",
        "    model_params = list(model.named_parameters())\n",
        "    # print('after model')\n",
        "\n",
        "    # we don't want weight decay for these\n",
        "    no_decay = ['bias', 'LayerNorm.weight', 'LayerNorm.bias']\n",
        "\n",
        "    optimizer_params = [\n",
        "        {'params': [p for n, p in model_params if n not in no_decay], \n",
        "        'weight_decay':0.001},\n",
        "        #  no weight decay should be applied\n",
        "        {'params': [p for n, p in model_params if n in no_decay],\n",
        "        'weight_decay':0.0}\n",
        "    ]\n",
        "\n",
        "    optimizer = AdamW(optimizer_params, lr=lr)\n",
        "\n",
        "    ###############change happens here#########################\n",
        "    # scheduler\n",
        "    num_train_steps = int(len(train_df)/ config.TRAIN_BATCH_SIZE / xm.xrt_world_size() * config.NUM_EPOCHS)\n",
        "    ###########################################################\n",
        "\n",
        "    xm.master_print(f'num_train_steps = {num_train_steps}, world_size = {xm.xrt_world_size()}')\n",
        "\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer=optimizer, \n",
        "                                                num_warmup_steps=0, \n",
        "                                                num_training_steps=num_train_steps)\n",
        "    # print('before epoch')\n",
        "    best_accuracy = 0.\n",
        "    for epoch in range(config.NUM_EPOCHS):\n",
        "        train_para_loader = pl.ParallelLoader(train_dl, [device])\n",
        "        valid_para_loader = pl.ParallelLoader(train_dl, [device])\n",
        "\n",
        "        start = time.time()\n",
        "        # print('before train')\n",
        "        train(train_para_loader.per_device_loader(device), model, optimizer, device, scheduler)\n",
        "        end = time.time()\n",
        "\n",
        "        xm.master_print(f'Training time: {end-start} secs')\n",
        "\n",
        "        fin_targs, fin_outs, losses = evaluate(valid_para_loader.per_device_loader(device), model, device)\n",
        "\n",
        "        # calc metrics\n",
        "        accuracy = accuracy_score(fin_targs, fin_outs)\n",
        "        macro_f1 = f1_score(fin_targs, fin_outs, average='macro')\n",
        "\n",
        "        # if epoch % 10 == 0:\n",
        "        xm.master_print(f'VALID ACCURACY: {accuracy}')\n",
        "        xm.master_print(f'VALID MACRO_F1: {macro_f1}')\n",
        "        \n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            xm.save(model.state_dict(), config.MODEL_PATH/'torch_xla_pretrained_camembert.bin')\n",
        "\n",
        "        # break"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHdDM9aQnuUf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "744a0b5b-ce8a-4151-88fc-f78745a6eec0"
      },
      "source": [
        "import gc; gc.collect()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1165"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xx4S9Soh2R-Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "9fdbad94-d726-460d-f4dd-801a79ba20d3"
      },
      "source": [
        "FLAGS = {}\n",
        "def mp_wrapper(rank, flags):\n",
        "    torch.set_default_tensor_type('torch.FloatTensor')\n",
        "    world_func()\n",
        "\n",
        "xmp.spawn(mp_wrapper, args=(FLAGS,), nprocs=8, start_method='fork')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num_train_steps = 796, world_size = 8\n",
            "Training time: 373.9767234325409 secs\n",
            "VALID ACCURACY: 0.8299528301886793\n",
            "VALID MACRO_F1: 0.7666145883370509\n",
            "Training time: 359.4210033416748 secs\n",
            "VALID ACCURACY: 0.8854952830188679\n",
            "VALID MACRO_F1: 0.8554114542066732\n",
            "Training time: 350.73388600349426 secs\n",
            "VALID ACCURACY: 0.9058962264150944\n",
            "VALID MACRO_F1: 0.8849048035940029\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaWe0dgDAdDe",
        "colab_type": "text"
      },
      "source": [
        "If you using a big model, declare the model above multiprocessor func as a global. Also cahnge the pytorch_xla version to nightlyn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8Cozp1poA3t",
        "colab_type": "text"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2iMtCPyOHn2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "outputId": "96182502-4fb1-40fc-eeb0-af3d9b32e570"
      },
      "source": [
        "test_df = pd.read_csv(config.COLAB_PATH/'SIGIR-2020-EComDC-release/data/x_test_task1_phase1.tsv', sep='\\t').fillna(' ')\n",
        "model_path = config.MODEL_PATH/'torch_xla_pretrained_camembert.bin'\n",
        "test_df['Prdlbl'] = 0\n",
        "test_df.sample(1)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Integer_id</th>\n",
              "      <th>Title</th>\n",
              "      <th>Description</th>\n",
              "      <th>Image_id</th>\n",
              "      <th>Product_id</th>\n",
              "      <th>Prdlbl</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>622</th>\n",
              "      <td>622</td>\n",
              "      <td>La Dame De Pique</td>\n",
              "      <td></td>\n",
              "      <td>1135788756</td>\n",
              "      <td>2313282280</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Integer_id             Title Description    Image_id  Product_id  Prdlbl\n",
              "622         622  La Dame De Pique              1135788756  2313282280       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFg1jN8hOS3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_ds = BertDataset((test_df.Title + 'xxfld' + test_df.Description).values, test_df.Prdlbl.values)\n",
        "\n",
        "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=config.VALID_BATCH_SIZE, \n",
        "                                        num_workers=4, shuffle=False)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FXQup9IPSju",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4fc58305-6b16-4b4a-fa05-f486ede64683"
      },
      "source": [
        "device = xm.xla_device()\n",
        "model = ClasModel(pretrained=True).to(device)\n",
        "model.load_state_dict(torch.load(str(model_path)))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QjPpGqGUD-a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6QWMJIrQPRJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "87ef0119da6445e0898f7c4e633b2f51",
            "019bb7e99ff3460cb7b2df8c2bf5d9d6",
            "e592c1e0d5af4a14936d26c44e3f3926",
            "f57dc7e3486246c5b35bb68ca65e4267",
            "3fd079c8e6854604ab345bab3fbc797f",
            "a4028ed53a7c41509b6182b1aba4b6b9",
            "1c54e43677b04db68c7434b6634d0e5e",
            "f3881c4f7f2f4bbcaaa7986bb39d495a"
          ]
        },
        "outputId": "699a45ec-716a-4beb-93c3-8749e6f14a2f"
      },
      "source": [
        "model.eval()\n",
        "\n",
        "fin_outs = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for bi, batch in tqdm(enumerate(test_dl), total=len(test_dl)):\n",
        "        ids = batch['ids']\n",
        "        mask = batch['mask']\n",
        "        targets = batch['targets']\n",
        "\n",
        "        ids = ids.to(device, dtype=torch.long)\n",
        "        mask = mask.to(device, dtype=torch.long)\n",
        "        targets = targets.to(device, dtype=torch.float)\n",
        "\n",
        "        # model.zero_grad()\n",
        "        out = model(ids, mask)\n",
        "\n",
        "        soft_out = nn.Softmax(dim=1)(out.cpu().detach())\n",
        "        out_np = soft_out.argmax(-1).numpy().tolist()\n",
        "\n",
        "        fin_outs.extend(out_np)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "87ef0119da6445e0898f7c4e633b2f51",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=59.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfao78djRG18",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "outputId": "60086d16-e383-4906-ed77-78d1c8f6ef81"
      },
      "source": [
        "sub_df = test_df.copy()\n",
        "sub_df['Prdtypecode'] = le.inverse_transform(fin_outs)\n",
        "sub_df.head()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Integer_id</th>\n",
              "      <th>Title</th>\n",
              "      <th>Description</th>\n",
              "      <th>Image_id</th>\n",
              "      <th>Product_id</th>\n",
              "      <th>Prdlbl</th>\n",
              "      <th>Prdtypecode</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Jeep Police - Gevarm-Gevarm</td>\n",
              "      <td></td>\n",
              "      <td>1193217616</td>\n",
              "      <td>3136702026</td>\n",
              "      <td>0</td>\n",
              "      <td>1300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Court Joyeux NoÃ«l En Peluche Taie Sofa Set Pad...</td>\n",
              "      <td>Joyeux NoÃ«l en peluche court Taie Sofa Set Pad...</td>\n",
              "      <td>1323615566</td>\n",
              "      <td>4231863665</td>\n",
              "      <td>0</td>\n",
              "      <td>1920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Sauna infrarouge Largo - 170 x 105 x 190 - Pin...</td>\n",
              "      <td>Dimensions : 150x105x190 cm ou 170x105x190 cm ...</td>\n",
              "      <td>1158121321</td>\n",
              "      <td>2695198357</td>\n",
              "      <td>0</td>\n",
              "      <td>2583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>BAGUE POUR LAME SOUS-SOLEUSE G. ET D.</td>\n",
              "      <td></td>\n",
              "      <td>1096607258</td>\n",
              "      <td>1657064583</td>\n",
              "      <td>0</td>\n",
              "      <td>2585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Carnet De Notes Bloc-Notes Cahierindian Squele...</td>\n",
              "      <td>Taille: En format A5 (144 cm x 21 cm) CaractÂ¿Â¿...</td>\n",
              "      <td>1303625028</td>\n",
              "      <td>4159071068</td>\n",
              "      <td>0</td>\n",
              "      <td>2522</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Integer_id  ... Prdtypecode\n",
              "0           0  ...        1300\n",
              "1           1  ...        1920\n",
              "2           2  ...        2583\n",
              "3           3  ...        2585\n",
              "4           4  ...        2522\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_ywN8KQSqtB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub_df[['Integer_id', 'Image_id', 'Product_id', 'Prdtypecode']].to_csv(config.DATA_PATH/'y_test_task1_phase1_pred.tsv', index=False, sep='\\t')"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDjqBh-CVAke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub_df[['Integer_id', 'Image_id', 'Product_id', 'Prdtypecode']].to_csv(config.COLAB_PATH/'y_test_task1_phase1_pred.tsv', index=False, sep='\\t')"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjogmqBMVDh9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "17016652-76a5-4318-d531-a8827344f1fe"
      },
      "source": [
        "sub_df[['Integer_id', 'Image_id', 'Product_id', 'Prdtypecode']]"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Integer_id</th>\n",
              "      <th>Image_id</th>\n",
              "      <th>Product_id</th>\n",
              "      <th>Prdtypecode</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1193217616</td>\n",
              "      <td>3136702026</td>\n",
              "      <td>1300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1323615566</td>\n",
              "      <td>4231863665</td>\n",
              "      <td>1920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1158121321</td>\n",
              "      <td>2695198357</td>\n",
              "      <td>2583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1096607258</td>\n",
              "      <td>1657064583</td>\n",
              "      <td>2585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1303625028</td>\n",
              "      <td>4159071068</td>\n",
              "      <td>2522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>932</th>\n",
              "      <td>932</td>\n",
              "      <td>450840330</td>\n",
              "      <td>50292005</td>\n",
              "      <td>2280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>933</th>\n",
              "      <td>933</td>\n",
              "      <td>1275609312</td>\n",
              "      <td>4006500599</td>\n",
              "      <td>1281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>934</th>\n",
              "      <td>934</td>\n",
              "      <td>1260304262</td>\n",
              "      <td>3893329037</td>\n",
              "      <td>2583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>935</th>\n",
              "      <td>935</td>\n",
              "      <td>931361182</td>\n",
              "      <td>185935391</td>\n",
              "      <td>2522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>936</th>\n",
              "      <td>936</td>\n",
              "      <td>1260480575</td>\n",
              "      <td>3893886625</td>\n",
              "      <td>2905</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>937 rows Ã— 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Integer_id    Image_id  Product_id  Prdtypecode\n",
              "0             0  1193217616  3136702026         1300\n",
              "1             1  1323615566  4231863665         1920\n",
              "2             2  1158121321  2695198357         2583\n",
              "3             3  1096607258  1657064583         2585\n",
              "4             4  1303625028  4159071068         2522\n",
              "..          ...         ...         ...          ...\n",
              "932         932   450840330    50292005         2280\n",
              "933         933  1275609312  4006500599         1281\n",
              "934         934  1260304262  3893329037         2583\n",
              "935         935   931361182   185935391         2522\n",
              "936         936  1260480575  3893886625         2905\n",
              "\n",
              "[937 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viI25DLyZJLy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "camembert_basic_xla.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP8xYjvnXSmN3vF0IH1fuAX"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojVNxYojvluc",
        "colab_type": "text"
      },
      "source": [
        "## CORE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ECpdOsxvpIL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install fastcore fastai2 transformers -q"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8n-epaRvstb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastcore.foundation import *\n",
        "from fastai2.text.all import *\n",
        "import transformers\n",
        "import pathlib"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRNfH41qvya5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@patch\n",
        "def ls(x: pathlib.Path):\n",
        "    return list(x.iterdir())"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiTyipOvcPQA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import os\n",
        "# from pathlib import Path\n",
        "from google.colab import drive"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nipZBIQ2amuD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_path(path):\n",
        "    if not os.path.isdir(path):\n",
        "        path.mkdir(parents=True, exist_ok=True)\n",
        "    return path"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SY8hz8XI_GDl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "colab_path = Path('/content')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jE3i8uUsdkvL",
        "colab_type": "text"
      },
      "source": [
        "handles all gdrive downloads for when running on cluster"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieIwxYONdo83",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "create_path(colab_path/'dataset');\n",
        "create_path(colab_path/'models');\n",
        "\n",
        "!git clone --quiet 'https://github.com/tezike/download_google_drive.git'\n",
        "os.chdir('download_google_drive')\n",
        "!python download_gdrive.py '10rH0nAxa7mWS289xIyRP-mOOowqiIolL' '../dataset/temp.tgz'\n",
        "shutil.rmtree('../download_google_drive')\n",
        "os.chdir('..')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQNK70EuxrRr",
        "colab_type": "text"
      },
      "source": [
        "## Colab_setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdKS3nNT0IKp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "0bbb1c2c-4015-4b4f-840d-de5c2145a755"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "root_dir = Path('/content/drive/My Drive')\n",
        "base_path = create_path(root_dir/'Rakuten')\n",
        "base_path"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('/content/drive/My Drive/Rakuten')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTjrkANjx9tM",
        "colab_type": "text"
      },
      "source": [
        "## download and untar data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMhQRUE0zfTR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -xzf $colab_path/'dataset/temp.tgz' # && tar -xzf ${colab_path/'lm-encoder-splits.tar.gz'} -C ${colab_path}"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNVdbQdYcYyv",
        "colab_type": "text"
      },
      "source": [
        "## FIN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKlgX2w5aXqo",
        "colab_type": "text"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saxAHHGZCWnf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Config():\n",
        "    def __init__(self):\n",
        "        self.MODEL_NAME = 'xlm-roberta-base'\n",
        "        self.LM_MODEL = transformers.XLMRobertaForMaskedLM.from_pretrained(self.MODEL_NAME)\n",
        "        self.CLAS_MODEL = transformers.XLMRobertaModel #.from_pretrained(MODEL_NAME)\n",
        "        self.TOKENIZER = transformers.XLMRobertaTokenizer.from_pretrained(\n",
        "                    pretrained_model_name_or_path=self.MODEL_NAME,\n",
        "                    do_lower_case=True,\n",
        "                    )\n",
        "        self.MODEL_CONFIG = transformers.XLMRobertaConfig.from_pretrained(self.MODEL_NAME)\n",
        "        self.COLAB_PATH = Path('/content')\n",
        "        self.BASE_PATH = base_path\n",
        "        self.DATA_PATH = create_path(base_path/'dataset')\n",
        "        self.MODEL_PATH = create_path(base_path/'models')\n",
        "        self.TEST_FILE = self.COLAB_PATH/'SIGIR-2020-EComDC-release/data/x_test_task1_phase1.tsv'\n",
        "        self.MAX_SEQ_LEN = 512\n",
        "        self.DEVICE = torch.device(f\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "config = Config()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCQNMKa1iP-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Config():\n",
        "    def __init__(self):\n",
        "        self.MODEL_NAME = 'roberta-base'\n",
        "        self.LM_MODEL = transformers.RobertaForMaskedLM.from_pretrained(self.MODEL_NAME)\n",
        "        self.CLAS_MODEL = transformers.RobertaForSequenceClassification #.from_pretrained(MODEL_NAME)\n",
        "        self.TOKENIZER = transformers.RobertaTokenizer.from_pretrained(\n",
        "                    pretrained_model_name_or_path=self.MODEL_NAME,\n",
        "                    do_lower_case=True,\n",
        "                    )\n",
        "        self.MODEL_CONFIG = transformers.RobertaConfig.from_pretrained(self.MODEL_NAME)\n",
        "        self.COLAB_PATH = Path('/content')\n",
        "        self.BASE_PATH = base_path\n",
        "        self.DATA_PATH = create_path(base_path/'dataset')\n",
        "        self.MODEL_PATH = create_path(base_path/'models')\n",
        "        self.TEST_FILE = self.COLAB_PATH/'SIGIR-2020-EComDC-release/data/x_test_task1_phase1.tsv'\n",
        "        self.MAX_SEQ_LEN = 512\n",
        "        self.DEVICE = torch.device(f\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "config_rob = Config()"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWPCguragmlm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# config.TOKENIZER.build_inputs_with_special_tokens(config.TOKENIZER.convert_tokens_to_ids(config.TOKENIZER.tokenize('he is a sheep', add_prefix_space=True)))"
      ],
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDro6neCfIzK",
        "colab_type": "text"
      },
      "source": [
        "## TOKENIZER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLAKbVsBe3c2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "e22cbd2c-f1fc-4cba-d453-3783f94bd20d"
      },
      "source": [
        "config.DATA_PATH.ls()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Path('/content/drive/My Drive/Rakuten/dataset/._SIGIR-2020-EComDC-release'),\n",
              " Path('/content/drive/My Drive/Rakuten/dataset/SIGIR-2020-EComDC-release'),\n",
              " Path('/content/drive/My Drive/Rakuten/dataset/temp.tgz'),\n",
              " Path('/content/drive/My Drive/Rakuten/dataset/rand_splits_10000_baseline.npy'),\n",
              " Path('/content/drive/My Drive/Rakuten/dataset/submission_baseline_10000_score_38.4.csv'),\n",
              " Path('/content/drive/My Drive/Rakuten/dataset/submission_baseline_10000_score_38.4.tsv'),\n",
              " Path('/content/drive/My Drive/Rakuten/dataset/rand_files_sample_10000.npy'),\n",
              " Path('/content/drive/My Drive/Rakuten/dataset/sample_df.csv'),\n",
              " Path('/content/drive/My Drive/Rakuten/dataset/df_all.csv')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Zn7-g_hjUdO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bef6e847-3c42-4e2c-dfed-75e6a23703c0"
      },
      "source": [
        "transformer_vocab = config.TOKENIZER.get_vocab()\n",
        "trans2fastai_vocab = [k for k, v in sorted(transformer_vocab.items(), key=lambda item: item[1])]\n",
        "len(trans2fastai_vocab)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "250002"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dX-mBCBrfLKb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HFTokenizer():\n",
        "    def __init__(self, tokenizer=config.TOKENIZER, seq_len=config.MAX_SEQ_LEN):\n",
        "        self.tok = tokenizer\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def tokenize(self, text):\n",
        "\n",
        "        tokens = self.tok.tokenize(text)\n",
        "\n",
        "        return tokens\n",
        "\n",
        "    def __call__(self, items:Str):\n",
        "        # ALways yeild the tokenized text before passing it to the Tokenizer Transform\n",
        "        tokenized = []\n",
        "        for text in items:\n",
        "            yield self.tokenize(text)[:self.seq_len-2]\n",
        "            # tokenized.append(self.tokenize(text)[:self.seq_len-2])\n",
        "        return tokenized"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sicOZTM8jNo3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Add_Special_Cls(Transform):\n",
        "    order = 7\n",
        "    def __init__(self, tokenizer=config.TOKENIZER):\n",
        "        self.tok = tokenizer\n",
        "\n",
        "    def encodes(self, o):\n",
        "        return TensorText(self.tok.build_inputs_with_special_tokens(list(o)))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRoFfKMFv3TN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@Tokenizer\n",
        "def decodes(self, o): return TitledStr(str(self.tokenizer.tok.convert_tokens_to_string(o)))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLsyn4UYj1LZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "custom_tokenizer = Tokenizer.from_df(text_cols=['Title', 'Description'], tok_func=HFTokenizer, rules=[fix_html], post_rules=[])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKB2UAc9HAIY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "outputId": "6c8737b0-2f84-475e-8af6-6f4e3a78e489"
      },
      "source": [
        "df_all = pd.read_csv(config.BASE_PATH/'dataset/df_all.csv'); df_all.sample(1)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Description</th>\n",
              "      <th>Image_id</th>\n",
              "      <th>Product_id</th>\n",
              "      <th>Prdtypecode</th>\n",
              "      <th>Prdlbl</th>\n",
              "      <th>image_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31150</th>\n",
              "      <td>Bebek Bébé En Peluche Hochets Poignée De Traction Jouer Jouets Lit Bébé Poussette Hanging Jeux Éducatifs 1388</td>\n",
              "      <td>Enfant en peluche hochets poignée de traction Jouer Jouets Lit bébé poussette Hanging Feature: 100% tout neuf et haute. Quantité: 1 Très doux et confortable au toucher Un grand jouet en peluche pour vos enfants grand cadeau pour l&amp;#39;anniversaire de mariage et bébé Taille: 11cmX7cm peut choisir: sous-marin fusée bateau de voiture Contenu: 1X Peluche animal bébé bébé enfants Clochettes hochets pour bébé Kid cadeau</td>\n",
              "      <td>1254358095</td>\n",
              "      <td>3861177097</td>\n",
              "      <td>1280</td>\n",
              "      <td>1280</td>\n",
              "      <td>/content/SIGIR-2020-EComDC-release/image/image_training/image_1254358095_product_3861177097.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                               Title  ...                                                                                       image_path\n",
              "31150  Bebek Bébé En Peluche Hochets Poignée De Traction Jouer Jouets Lit Bébé Poussette Hanging Jeux Éducatifs 1388  ...  /content/SIGIR-2020-EComDC-release/image/image_training/image_1254358095_product_3861177097.jpg\n",
              "\n",
              "[1 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9XkZVpTlRlx",
        "colab_type": "text"
      },
      "source": [
        "# MLM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-AKmr5glTGj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MLM(Transform):\n",
        "    def __init__(self, tokenizer, mlm_prob=0.15, mask_prob = 0.8):\n",
        "        \"\"\" Prepare masked tokens inputs/labels for masked language modeling: 80% MASK, 10% random, 10% original. \"\"\"\n",
        "\n",
        "        self.tokenizer = tokenizer\n",
        "        self.mlm_prob, self.mask_prob = mlm_prob, mask_prob\n",
        "\n",
        "        if self.tokenizer.mask_token is None:\n",
        "            raise ValueError(\n",
        "                \"This tokenizer does not have a mask token which is necessary for masked language modeling. Remove the --mlm flag if you want to use this tokenizer.\"\n",
        "            )\n",
        "\n",
        "    def prob_matrix(self, inputs):\n",
        "        labels = inputs.clone()\n",
        "        # We sample a few tokens in each sequence for masked-LM training (with probability args.mlm_probability defaults to 0.15 in Bert/RoBERTa)\n",
        "        probability_matrix = torch.full(labels.shape, self.mlm_prob)\n",
        "        # print(probability_matrix)\n",
        "        special_tokens_mask = self.tokenizer.get_special_tokens_mask(labels.tolist(), already_has_special_tokens=True)\n",
        "        # place 0 at the places where we have these special tookens\n",
        "        probability_matrix.masked_fill_(torch.tensor(special_tokens_mask, dtype=torch.bool), value=0.0)\n",
        "        if self.tokenizer.pad_token is not None:\n",
        "            # check if the any element in input is equal to the pad token\n",
        "            padding_mask = labels.eq(self.tokenizer.pad_token_id)\n",
        "            # if a pad tok is hit, fill the prob_mat with 0.0 for that pad so the model won't attend to it\n",
        "            probability_matrix.masked_fill_(padding_mask, value=0.0)\n",
        "\n",
        "        return probability_matrix, labels\n",
        "\n",
        "    def encodes(self, inputs):\n",
        "        probability_matrix, labels = self.prob_matrix(inputs)\n",
        "\n",
        "        # use a prop dist to select points in the input sentence token that we want to mask. convert these binary points to bool\n",
        "        masked_indices = torch.bernoulli(probability_matrix).bool()\n",
        "        # anyplace that isn't a mask, replace with -100 so loss won't be computed on it\n",
        "        labels[~masked_indices] = -100  # We only compute loss on masked tokens\n",
        "        # # 80% of the time, we replace masked input tokens with tokenizer.mask_token ([MASK])\n",
        "        # out of the mask_indices, select a percentage that will be masked\n",
        "        indices_replaced = torch.bernoulli(torch.full(labels.shape, self.mask_prob)).bool() & masked_indices\n",
        "\n",
        "        # replace all the mask hits in the original input with the mask token id\n",
        "        inputs[indices_replaced] = self.tokenizer.convert_tokens_to_ids(self.tokenizer.mask_token)\n",
        "\n",
        "        # # 10% of the time, we replace masked input tokens with random word\n",
        "        # replace the previous masks a percentage of the time making sure the tokens to be replaced are not in the sub mask we just created\n",
        "        indices_random = torch.bernoulli(torch.full(labels.shape, 0.5)).bool() & masked_indices & ~indices_replaced\n",
        "        # get out some random token\n",
        "        random_words = torch.randint(len(self.tokenizer), labels.shape, dtype=torch.long)\n",
        "        # replace the some of the masked inputs with random words\n",
        "        inputs[indices_random] = random_words[indices_random]\n",
        "\n",
        "        # # The rest of the time (10% of the time) we keep the masked input tokens unchanged\n",
        "        return inputs, labels"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cFu-4UNrMq8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@Numericalize\n",
        "def decodes(self, o):\n",
        "    '''set the new mask at positions where the token_ids is -100'''\n",
        "    tmp_vocab = self.vocab.copy()\n",
        "    \n",
        "    tmp_vocab.append('<loss_mask>')\n",
        "\n",
        "    o = [-1 if o_ == -100 else o_ for o_ in o]\n",
        "    return (tmp_vocab[o_] for o_ in o if tmp_vocab[o_] != config.TOKENIZER.pad_token_id)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ob-NDAMhv5lY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_input_chunk(samples, pad_idx=1, pad_first=True, seq_len=config.MAX_SEQ_LEN):\n",
        "    \"Pad `samples` by adding padding by chunks of size `seq_len`\"\n",
        "    max_len = max([len(s[0]) for s in samples])\n",
        "    def _f(x):\n",
        "        l = max_len - x.shape[0]\n",
        "        pad_chunk = x.new_zeros((l//seq_len) * seq_len) + pad_idx\n",
        "        pad_res   = x.new_zeros(l % seq_len) + pad_idx\n",
        "        x1 = torch.cat([pad_chunk, x, pad_res]) if pad_first else torch.cat([x, pad_res, pad_chunk])\n",
        "        return retain_type(x1, x)\n",
        "    return [(_f(s[0]), _f(s[1])) for s in samples]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1XGEGLE1YIY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pad = partial(pad_input_chunk, pad_idx=config.TOKENIZER.pad_token_id, pad_first=False, seq_len=config.MAX_SEQ_LEN)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AAn_FT5diJU",
        "colab_type": "text"
      },
      "source": [
        "##DAtaset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCLdqA-wwrlh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "splits = RandomSplitter()(df_all[:500])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhkzRPSgMfsc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfms = [attrgetter('text'), \n",
        "            custom_tokenizer, Numericalize(vocab=trans2fastai_vocab), \n",
        "            Add_Special_Cls, MLM(config.TOKENIZER)]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBdbpgQrj7bL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "be610f45-61d3-4671-910d-ec1aa150f3db"
      },
      "source": [
        "dsets = TfmdLists(df_all[:500], tfms, splits=splits, dl_type=SortedDL)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IO1Tvjqzw9On",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "7e2d3203-8008-4e0a-b550-c5ef5b8e7e96"
      },
      "source": [
        "dsets.decode(dsets[0])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(\"<s> xxfld<mask> journal des arts (le) n° 133 du 28/09/2001 - l<mask>art<mask> son<mask> salon<mask>'<mask> asiatique a<mask>is - ja<mask>ques barre клієнт - francois perrier<mask> la reforme des vente<mask> aux<mask>cheres publiques - le sna fete ses cent ans. xxfl<mask> 2<mask></s>\",\n",
              " \"<s><loss_mask><loss_mask><loss_mask> 1<loss_mask><loss_mask><loss_mask><loss_mask><loss_mask><loss_mask><loss_mask><loss_mask><loss_mask><loss_mask><loss_mask><loss_mask><loss_mask><loss_mask><loss_mask>'<loss_mask> et<loss_mask> marche<loss_mask> d<loss_mask>art<loss_mask><loss_mask><loss_mask> par<loss_mask><loss_mask><loss_mask>c<loss_mask><loss_mask>re<loss_mask><loss_mask><loss_mask><loss_mask><loss_mask> -<loss_mask><loss_mask>e<loss_mask><loss_mask>s<loss_mask> en<loss_mask><loss_mask><loss_mask><loss_mask><loss_mask><loss_mask><loss_mask><loss_mask><loss_mask><loss_mask><loss_mask><loss_mask><loss_mask><loss_mask>d<loss_mask> nan</s>\")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ytdjSqpzJzO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dls = dsets.dataloaders(bs=3, before_batch=[pad])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NdAB3BmPV9A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b = dls.one_batch()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqITIUlD0uxg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dls.show_batch()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipYClJt216ub",
        "colab_type": "text"
      },
      "source": [
        "## Language Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLg9qJEh18H7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MLModel(nn.Module):\n",
        "    def __init__(self, model=config.LM_MODEL, tokenizer=config.TOKENIZER):\n",
        "        super(MLModel, self).__init__()\n",
        "        self.model = model\n",
        "\n",
        "    def forward(self, inp):\n",
        "        attention_mask = (inp != config.TOKENIZER.pad_token_id).type(inp.type()) \n",
        "        out = self.model(inp, attention_mask=attention_mask)\n",
        "        return out[0]"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnfKJAlW4FFg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = MLModel()\n",
        "\n",
        "opt_func = partial(Adam, decouple_wd=True)\n",
        "\n",
        "loss_func = CrossEntropyLossFlat()\n",
        "\n",
        "learn = Learner(dls, model, loss_func=loss_func, opt_func=opt_func,metrics=[accuracy, perplexity]).to_fp16()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9YGTQhQIVM6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "059860a8-9e67-4773-a99e-e2044accb76c"
      },
      "source": [
        "import gc; gc.collect()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "830"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jlis-UY45NxC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "0fc18b39-db6b-44b5-f2d7-80ec4ad16ff9"
      },
      "source": [
        "learn.lr_find()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SuggestedLRs(lr_min=5.754399462603033e-05, lr_steep=2.75422871709452e-06)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKmhwcXR5_hV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# learn.summary()"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cd0-JlOp6G9Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# learn.validate()"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TxshfSL6KE6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "fa3a1844-694c-4ac9-cc10-634c6aa1d819"
      },
      "source": [
        "learn.fit_one_cycle(3, lr_max=1e-4)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.912897</td>\n",
              "      <td>2.095650</td>\n",
              "      <td>0.120566</td>\n",
              "      <td>8.130728</td>\n",
              "      <td>29:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.617106</td>\n",
              "      <td>1.666066</td>\n",
              "      <td>0.129951</td>\n",
              "      <td>5.291311</td>\n",
              "      <td>29:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.348014</td>\n",
              "      <td>1.527953</td>\n",
              "      <td>0.132507</td>\n",
              "      <td>4.608732</td>\n",
              "      <td>29:10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlCzB52TEOeB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2dc9a38d-2391-42dd-a8e5-6133bd42978f"
      },
      "source": [
        "learn.path = config.MODEL_PATH;\n",
        "learn.path"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('/content/drive/My Drive/Rakuten/models')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLGPcAGMDxF8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# learn.save('This is the encoder')\n",
        "learn.export(fname='roberta_pretrained_lm.pkl')"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivm0yiAKHNoN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3d4e7c96-f8a3-4205-952b-e4b90438c85d"
      },
      "source": [
        "learn.show_results(max_n=1)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>text_</th>\n",
              "      <th>text__</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;s&gt;xxfld 1 5dfull&lt;mask&gt;int&lt;mask&gt; de broder&lt;mask&gt; en strass diamant bricolage pasted peinture&lt;mask&gt; de croix sweetheart93 xxfld 2 5&lt;mask&gt; bro&lt;mask&gt;ie peint&lt;mask&gt;&lt;mask&gt;&lt;mask&gt; diamant bricolage pasted peinture point&lt;mask&gt; croix description&lt;mask&gt; marque n&lt;mask&gt;velle et de haute qualité la qualité&lt;mask&gt;&lt;mask&gt;le de canvasgood&lt;mask&gt;ologique de la pe&lt;mask&gt;ure de&lt;mask&gt;&lt;mask&gt;. coloré et belle toile perception.the visuelle pattern5d sont&lt;mask&gt;orno lum&lt;mask&gt;ux dou Guards fadingnot facile&lt;mask&gt; tractsvenir fuzzing ou cassé.&lt;mask&gt;fait pour dé&lt;mask&gt;r votre salon ou&lt;mask&gt;ambre à&lt;mask&gt;cher pour correspondre à différentes peinture style.&lt;mask&gt;iy décoration sera&lt;mask&gt;int avec des paillettes résine sequinsresin lustre unique est dazzlingshining dans le light&lt;mask&gt; actpherlementabit plus pop&lt;mask&gt;&lt;mask&gt; décoration bricolage.rientériel: strass + couleur toile: comme le&lt;mask&gt;re taille canvas: h: 30x30&lt;mask&gt; production bricolage peinture diam&lt;mask&gt;&lt;mask&gt;iveaux1. ouv&lt;mask&gt; l&amp;'&lt;mask&gt;ballage et&lt;mask&gt;érifier le diamant&lt;mask&gt;age tools&lt;mask&gt;&lt;mask&gt;&lt;mask&gt;écial&lt;mask&gt; voir la résine diamant colorarranged af&lt;mask&gt; mesh coding.3. dévo&lt;mask&gt;z dessin de bande ci-d&lt;mask&gt;us vous&lt;mask&gt;rez&lt;mask&gt;auc&lt;mask&gt; de symboles correspondant à la coding.4 couleur&lt;mask&gt; selon&lt;mask&gt; pince&lt;mask&gt; cod&lt;mask&gt; de couleur correspond&lt;mask&gt; au correspondant du diamonds.5 incrusté de résine. a suggé&lt;mask&gt; qu&amp;&lt;mask&gt;un type de diamant de r&lt;mask&gt;ine</td>\n",
              "      <td>&lt;s&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt; pe&lt;loss_mask&gt;ures&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;ie&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt; point&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;d&lt;loss_mask&gt;der&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;ures strass&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt; de&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;:&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;ou&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt; naturel&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt; ec&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;int&lt;loss_mask&gt;&lt;loss_mask&gt; diamant&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;ont col&lt;loss_mask&gt;&lt;loss_mask&gt;ine&lt;loss_mask&gt;&lt;loss_mask&gt;x&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt; de de&lt;loss_mask&gt;&lt;loss_mask&gt; fuzz&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt; par&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;core&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt; ch&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt; cou&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;d&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt; pe&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;is&lt;loss_mask&gt;uellement le&lt;loss_mask&gt;&lt;loss_mask&gt;ulaire&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt; mat&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt; mont&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;cm&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;ant n&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;rez&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;em&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt; v&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt; tir&lt;loss_mask&gt;&lt;loss_mask&gt;.2 sp&lt;loss_mask&gt;&lt;loss_mask&gt;.&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;in de&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;ile&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;ess&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt; ver&lt;loss_mask&gt; be&lt;loss_mask&gt;oup&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;.&lt;loss_mask&gt;lon la&lt;loss_mask&gt;&lt;loss_mask&gt; à&lt;loss_mask&gt;age&lt;loss_mask&gt; cou&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;ant&lt;loss_mask&gt; correspond&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;ré&lt;loss_mask&gt;&lt;loss_mask&gt;'&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;és&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;6&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;draw&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;ant&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt; ensemble&lt;loss_mask&gt;&lt;loss_mask&gt; un&lt;loss_mask&gt;ul&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt; symb&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;ent&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;.&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;ins&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;é&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt; above&lt;loss_mask&gt;&lt;loss_mask&gt; maté&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;ures&lt;loss_mask&gt;&lt;loss_mask&gt; à&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;do&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt; fight&lt;loss_mask&gt;&lt;loss_mask&gt; l&lt;loss_mask&gt;&lt;loss_mask&gt;é&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;loss_mask&gt;&lt;/s&gt;</td>\n",
              "      <td>&lt;s&gt;xxfld 1 5dfld peinture de broderie en strass diamant bricolage pasted peinture point de croix sweetheart93 xxfld 2 5d broderie peinture strass diamant bricolage pasted peinture point de croix description: marque nouvelle et de haute qualité la qualité de taille de canvas. technologique de la peinture de crois. coloré et belle toile design.the visuelle pattern5d sont s de lumineux doux.. facile à devenir fuzzing ou cassé. parfait pour décorer votre salon ou chambre à coucher pour correspondre à différentes peinture style.cette décoration sera peint avec des paillettes résine sequinsresin lustre unique est sparkershining dans le light. actuellement est plus popable de décoration bricolage. matériel: strass + couleur toile: comme le livre taille canvas: h: 30x30cm production bricolage peinture diamant niveaux1. ouvrez l&amp;'emballage et vérifier le diamant lavage tools2. spécialement voir la résine diamant colorarranged afin mesh coding.3. dévoitez dessin de bande ci-dessus vous offrez beaucoup de symboles correspondant à la coding.4 couleur: selon le pince de codifications de couleur correspondant au correspondant du diamonds.5 incrusté de résine. a suggéré qu&amp;'un type de diamant de résine une série complète design.6. afin de créer un des stockings de diamant parfait misé dans le seul endroit tous les symboles de ligne ne doivent pas rester diamonds.7 coincéable pour couper une bonne figure sur les dessins tenir ensemble montré sur le grand plan du diamond.8 matériel. épissant besoin et plat contre le bon ne pas 7.9. après un bon repos de diamondsthe de l&amp;'écart au symbole correspondant de&lt;/s&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SmamJwt6ZNE",
        "colab_type": "text"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z05KORIZUtAM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "852ad43a-846d-47d1-9ad5-61b4dfc232eb"
      },
      "source": [
        "df_all.Title[9]"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Contrôleur De Jeu Mobile Tir Sensible Et But Joysticks Poignée Gamepad Pour Pubg'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nns81038qba",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "masked_text = 'Contrôleur De Jeu Mobile Tir Sensible Et But <mask> Poignée Gamepad Pour Pubg'"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rl1bvcvKWU_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "masked_text = \"C'est un mot français que je viens de <mask>\""
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFNWjBgj6a2y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "2eef8f1f-0f04-430e-f8ab-ee261dcb95e5"
      },
      "source": [
        "masked_tokens = custom_tokenizer.encodes(masked_text)\n",
        "masked_token_ids = Numericalize(vocab=trans2fastai_vocab)(masked_tokens)\n",
        "masked_token_ids = Add_Special_Cls()(masked_token_ids)\n",
        "\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    out = learn.model(masked_token_ids[None].cuda())\n",
        "# get the probability of the logits predicted where the mask occurs\n",
        "masked_index = torch.where(masked_token_ids == config.TOKENIZER.mask_token_id)[0].numpy().item()\n",
        "# print(masked_tokens)\n",
        "# print(masked_index)\n",
        "logits = out[:, masked_index, :]\n",
        "out = F.softmax(logits, dim=1)\n",
        "# get the top k preds\n",
        "score, pred = out.topk(5)\n",
        "\n",
        "result = []\n",
        "\n",
        "for i, (score_, pred_) in enumerate(zip(score[0].tolist(), pred[0].tolist())):\n",
        "    tokens = masked_token_ids.numpy()\n",
        "    tokens[masked_index] = pred_\n",
        "    tokens = tokens[np.where(tokens != config.TOKENIZER.pad_token_id)]\n",
        "    w = dsets.decode(tokens)\n",
        "    print(f'Input: {masked_text}')\n",
        "    print(f'Pred: {w}')\n",
        "    print(f'score= {score_} \\n')"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: C'est un mot français que je viens de <mask>\n",
            "Pred: <s>c'est un mot français que je viens deux</s>\n",
            "score= 0.04931799694895744 \n",
            "\n",
            "Input: C'est un mot français que je viens de <mask>\n",
            "Pred: <s>c'est un mot français que je viens de jour</s>\n",
            "score= 0.03146360442042351 \n",
            "\n",
            "Input: C'est un mot français que je viens de <mask>\n",
            "Pred: <s>c'est un mot français que je viens de plus</s>\n",
            "score= 0.029756130650639534 \n",
            "\n",
            "Input: C'est un mot français que je viens de <mask>\n",
            "Pred: <s>c'est un mot français que je viens de.</s>\n",
            "score= 0.022600935772061348 \n",
            "\n",
            "Input: C'est un mot français que je viens de <mask>\n",
            "Pred: <s>c'est un mot français que je viens de …</s>\n",
            "score= 0.021387362852692604 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQ_KjVy0MR_c",
        "colab_type": "text"
      },
      "source": [
        "# Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgDvkdC7XdmU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_input_chunk(samples, pad_idx=1, pad_first=True, seq_len=72):\n",
        "    \"Pad `samples` by adding padding by chunks of size `seq_len`\"\n",
        "    max_len = max([len(s[0]) for s in samples])\n",
        "    def _f(x):\n",
        "        l = max_len - x.shape[0]\n",
        "        pad_chunk = x.new_zeros((l//seq_len) * seq_len) + pad_idx\n",
        "        pad_res   = x.new_zeros(l % seq_len) + pad_idx\n",
        "        x1 = torch.cat([pad_chunk, x, pad_res]) if pad_first else torch.cat([x, pad_res, pad_chunk])\n",
        "        return retain_type(x1, x)\n",
        "    return [(_f(s[0]), *s[1:]) for s in samples]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoGDk7BRXc3b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pad = partial(pad_input_chunk, pad_idx=config.TOKENIZER.pad_token_id, pad_first=False, seq_len=config.MAX_SEQ_LEN)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2YX5NAiMUEj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfms = [attrgetter('text'), \n",
        "            custom_tokenizer, Numericalize(vocab=trans2fastai_vocab), \n",
        "            Add_Special_Cls]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WOi5d6FL2CB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "splits = RandomSplitter()(df_all)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4POr_fL2SoW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "b89a0f65-c239-4e16-91b7-02ec8b9f107e"
      },
      "source": [
        "dsets = Datasets(df_all, tfms=[tfms, [attrgetter('Prdlbl'), Categorize]], splits=splits, dl_type=SortedDL)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNE912a_3-To",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dls_clas = dsets.dataloaders(bs=4, val_bs=4, before_batch=[pad], seq_len=config.MAX_SEQ_LEN)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N49AB5Qa4Myk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        },
        "outputId": "dfbd7074-cd0d-4ade-d5d1-393457f1f8e3"
      },
      "source": [
        "dls_clas.show_batch()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;s&gt; xxfld 1 décoration du foyer coussin trou noir stellaire taie d'oreiller jeter covers cc4440 xxfld 2 décoration du foyer coussin stellar trou noir taie coussin couvre point de vente de produits: décoration de la maison: throw taies d&amp;'oreiller sont perfert pour décorer votre chambre .suitable pour le salon chambre à coucher un canapé un canapé voiture siège sol banc bureau café partie ect. fermeture à glissière est caché et smoothly.putting votre insert dans puis de nouveaux coussins pourrait terminée. insert d&amp;'oreiller pourrait facilement être frappé légèrement ou enlevé vous pouvez laver taie d&amp;'oreiller en tout temps de sorte que votre oreiller jet pourrait toujours garder propre et belle. conseils de lavage: lavage en machine à froid séparément doucement cycle seulement dot non eau de javel sèche-linge ne pas repasser et il va tout nouveau look. le motif imprimé est disponible uniquement sur la face avant arrière sans impression grand</td>\n",
              "      <td>1920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;s&gt; xxfld 1 peinture décorative salle de bedroomliving tv murale décoration murale mureaux xxfld 2 peinture décorative salle de bedroomliving tv murale décoration murale mureaux caractéristiques: 100% tout neuf et de haute qualité. quantité: 1pc protection non toxique environnement imperméable matière: pvc motif: avion autocollant mural facile à appliquer supprimer déplacer et réutiliser sans laisser de dommage ou de résidus. la taille mesurée manuellement. la tolérance est de 1 cm. peut être appliqué sur toute surface sans poussière lisse sec comme porte en verre vitre carreaux de céramique dans la cuisine ou salle de bain lunettes appareils ménagers air conditionné et le corps de voiture nous faisons de notre meilleur spectacle du produit réel. mais s&amp;'il vous plaît comprendre la couleur encore peut-être un peu différent selon l&amp;'effet illustration et de l&amp;'écran. un sticker mural art mur beautiflu pour votre maison ou au bureau donnera à votre pièce un aspect</td>\n",
              "      <td>2060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;s&gt; xxfld 1 papier peint | fond illuminé | 300x231 | | xxfld 2 &lt;strong&gt;papier peint&lt;/strong&gt; intissé \"fond illuminé\" solide résistant à l&amp;'eau et aux rayures est à poser au mur. papier peint intissé \"fond illuminé\" représentant un motif inspiré sera une décoration particulière pour toutes les pièces. les papiers peints intissés sont posés au mur avec une colle speciale .celui-ci peut être posé dans chaque pièce une salle de bain et dans la cuisine. il se distingue par une surface demi terne et couvre les imperfections du mur. &lt;strong&gt;impression de la haute qualité&lt;/strong&gt; l&amp;'impression numérique de la résolution de 600dpi dans la technologie unique et les couleurs vives de papier peint intissé font remplir votre mur et agrandir votre intérieur. celui-ci forme une couche isolante et permet aux murs de respirer. l&amp;'impression résistante à l&amp;'eau est très durable. &lt;strong&gt;eco et en sécurité&lt;/strong&gt; en utilisant des matériaux fiables nos papiers</td>\n",
              "      <td>2060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;s&gt; xxfld 1 v-rally 4 - jeu en téléchargement xxfld 2 &lt;div&gt; &lt;p&gt;&lt;strong&gt;note :&lt;/strong&gt; un compte steam et une connexion internet sont nécessaires pour activer télécharger et utiliser ce produit.&lt;/p&gt; offre de précommande &lt;div&gt; &lt;p&gt;profitez d&amp;'un accès anticipé à la légendaire ford shelby gt500&lt;/p&gt; &lt;/div&gt; à propos du jeu &lt;p&gt;le retour d&amp;'une légende des jeux de course off-road ! vivez une expérience extrême en maîtrisant une simulation exigeante. relevez les défis du rallye du rallycross du drift du buggy ou de l&amp;'hill climb et partez pour un voyage spectaculaire sur tous les continents.&lt;/p&gt; &lt;p&gt;dominez des routes dangereuses des conditions et des environnements hostiles recherchez toujours plus de vitesse et laissez l&amp;'adrénaline booster vos réflexes. au volant des bolides off-road les plus mythiques de chaque catégorie affrontez les tracés les plus difficiles dans de fabuleux décors.&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;strong&gt;rallye :&lt;/strong&gt; du kenya à sequoia park dominez les tracés les plus difficiles dans des</td>\n",
              "      <td>2905</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnBN29Xr5bfi",
        "colab_type": "text"
      },
      "source": [
        "## For clas learner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiDJTDVHP49v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def roberta_cls_splitter(m):\n",
        "    \"Split the classifier head from the backbone\"\n",
        "    groups = [nn.Sequential(m.model.embeddings,\n",
        "                  m.model.encoder.layer[0],\n",
        "                  m.model.encoder.layer[1],\n",
        "                  m.model.encoder.layer[2],\n",
        "                  m.model.encoder.layer[3],\n",
        "                  m.model.encoder.layer[4],\n",
        "                  m.model.encoder.layer[5],\n",
        "                  m.model.encoder.layer[6],\n",
        "                  m.model.encoder.layer[7],\n",
        "                  m.model.encoder.layer[8],\n",
        "                  m.model.encoder.layer[9],\n",
        "                  m.model.encoder.layer[10],\n",
        "                  m.model.encoder.layer[11],\n",
        "                  m.model.pooler)]\n",
        "    groups = L(groups + [m.lin])\n",
        "    return groups.map(params)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0eEXX7ZdD-B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Clas_Model(nn.Module):\n",
        "    def __init__(self, pretrained=True, num_classes=dls_clas.c, load_encoder=True):\n",
        "        super(Clas_Model, self).__init__()\n",
        "        if pretrained:\n",
        "            self.model = config.CLAS_MODEL(config.MODEL_CONFIG)\n",
        "\n",
        "        else: \n",
        "            self.model = config.CLAS_MODEL.from_pretrained(config.MODEL_NAME)\n",
        "\n",
        "        if load_encoder: self.load_lm_encoder(self.model, config.MODEL_PATH/'roberta_pretrained_lm.pkl')\n",
        "        \n",
        "        self.drop = nn.Dropout(0.2)\n",
        "\n",
        "        self.lin = nn.Linear(768*2, num_classes)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        attention_mask =  (x!=config.TOKENIZER.pad_token_id).type(x.type())\n",
        "\n",
        "        h_0, _ = self.model(x, attention_mask=attention_mask)\n",
        "        \n",
        "        mean_pool = torch.mean(h_0, 1)\n",
        "\n",
        "        max_pool = torch.max(h_0, 1)[0]\n",
        "\n",
        "        out = torch.cat([mean_pool, max_pool], 1)\n",
        "\n",
        "        out = self.lin(self.drop(out))\n",
        "\n",
        "        return out\n",
        "\n",
        "    def load_lm_encoder(self,clas_model, lm_path=None):\n",
        "        clas_model_dict = clas_model.state_dict()\n",
        "        if lm_path is not None:\n",
        "            lm_model_dict = torch.load(lm_path).model.state_dict()\n",
        "            needed_dict = {k[6:]:v for k, v in lm_model_dict.items() if str(k)[6:] in clas_model_dict.keys()}\n",
        "            clas_model_dict.update(needed_dict)\n",
        "        clas_model.load_state_dict(clas_model_dict)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAm361lhwYt9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Clas_Model(pretrained=True, load_encoder=False)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQEFWD3J71SF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt_func = partial(Adam, decoupled_wd=True) #AdamW\n",
        "learn = Learner(dls_clas, model, metrics=accuracy, drop_mult=0., loss_func=CrossEntropyLossFlat(), opt_func=opt_func)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUcr8EQI9MSk",
        "colab_type": "text"
      },
      "source": [
        "Make only the last layer trainable then gradually unfreeze the rest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCPj72RtDDKL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# learn.freeze()"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMhoC53U8mEk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c786b10b-9399-4e68-97eb-8258cb00fd42"
      },
      "source": [
        "learn.summary()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Clas_Model (Input shape: ['4 x 87'])\n",
              "================================================================\n",
              "Layer (type)         Output Shape         Param #    Trainable \n",
              "================================================================\n",
              "Embedding            4 x 87 x 768         192,001,536 True      \n",
              "________________________________________________________________\n",
              "Embedding            4 x 87 x 768         394,752    True      \n",
              "________________________________________________________________\n",
              "Embedding            4 x 87 x 768         768        True      \n",
              "________________________________________________________________\n",
              "LayerNorm            4 x 87 x 768         1,536      True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 87 x 768         0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 12 x 87 x 87     0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "LayerNorm            4 x 87 x 768         1,536      True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 87 x 768         0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 3072        2,362,368  True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         2,360,064  True      \n",
              "________________________________________________________________\n",
              "LayerNorm            4 x 87 x 768         1,536      True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 87 x 768         0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 12 x 87 x 87     0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "LayerNorm            4 x 87 x 768         1,536      True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 87 x 768         0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 3072        2,362,368  True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         2,360,064  True      \n",
              "________________________________________________________________\n",
              "LayerNorm            4 x 87 x 768         1,536      True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 87 x 768         0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 12 x 87 x 87     0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "LayerNorm            4 x 87 x 768         1,536      True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 87 x 768         0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 3072        2,362,368  True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         2,360,064  True      \n",
              "________________________________________________________________\n",
              "LayerNorm            4 x 87 x 768         1,536      True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 87 x 768         0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 12 x 87 x 87     0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "LayerNorm            4 x 87 x 768         1,536      True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 87 x 768         0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 3072        2,362,368  True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         2,360,064  True      \n",
              "________________________________________________________________\n",
              "LayerNorm            4 x 87 x 768         1,536      True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 87 x 768         0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 12 x 87 x 87     0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "LayerNorm            4 x 87 x 768         1,536      True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 87 x 768         0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 3072        2,362,368  True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         2,360,064  True      \n",
              "________________________________________________________________\n",
              "LayerNorm            4 x 87 x 768         1,536      True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 87 x 768         0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 12 x 87 x 87     0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "LayerNorm            4 x 87 x 768         1,536      True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 87 x 768         0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 3072        2,362,368  True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         2,360,064  True      \n",
              "________________________________________________________________\n",
              "LayerNorm            4 x 87 x 768         1,536      True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 87 x 768         0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 12 x 87 x 87     0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "LayerNorm            4 x 87 x 768         1,536      True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 87 x 768         0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 3072        2,362,368  True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         2,360,064  True      \n",
              "________________________________________________________________\n",
              "LayerNorm            4 x 87 x 768         1,536      True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 87 x 768         0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 12 x 87 x 87     0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "LayerNorm            4 x 87 x 768         1,536      True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 87 x 768         0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 3072        2,362,368  True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         2,360,064  True      \n",
              "________________________________________________________________\n",
              "LayerNorm            4 x 87 x 768         1,536      True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 87 x 768         0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 12 x 87 x 87     0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "LayerNorm            4 x 87 x 768         1,536      True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 87 x 768         0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 3072        2,362,368  True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         2,360,064  True      \n",
              "________________________________________________________________\n",
              "LayerNorm            4 x 87 x 768         1,536      True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 87 x 768         0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 12 x 87 x 87     0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "LayerNorm            4 x 87 x 768         1,536      True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 87 x 768         0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 3072        2,362,368  True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         2,360,064  True      \n",
              "________________________________________________________________\n",
              "LayerNorm            4 x 87 x 768         1,536      True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 87 x 768         0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 12 x 87 x 87     0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "LayerNorm            4 x 87 x 768         1,536      True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 87 x 768         0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 3072        2,362,368  True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         2,360,064  True      \n",
              "________________________________________________________________\n",
              "LayerNorm            4 x 87 x 768         1,536      True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 87 x 768         0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 12 x 87 x 87     0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "LayerNorm            4 x 87 x 768         1,536      True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 87 x 768         0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 3072        2,362,368  True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         2,360,064  True      \n",
              "________________________________________________________________\n",
              "LayerNorm            4 x 87 x 768         1,536      True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 87 x 768         0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 768              590,592    True      \n",
              "________________________________________________________________\n",
              "Tanh                 4 x 768              0          False     \n",
              "________________________________________________________________\n",
              "Dropout              4 x 1536             0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 27               41,499     True      \n",
              "________________________________________________________________\n",
              "\n",
              "Total params: 278,085,147\n",
              "Total trainable params: 278,085,147\n",
              "Total non-trainable params: 0\n",
              "\n",
              "Optimizer used: functools.partial(<function Adam at 0x7fe06187bbf8>, decoupled_wd=True)\n",
              "Loss function: FlattenedLoss of CrossEntropyLoss()\n",
              "\n",
              "Callbacks:\n",
              "  - TrainEvalCallback\n",
              "  - Recorder\n",
              "  - ProgressCallback"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRaD3d_kHyYo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a492d282-e17b-4201-f280-9dcde98ff9b0"
      },
      "source": [
        "import gc; \n",
        "gc.collect()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "792"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "At5Cdg037aUQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "6f220587-0896-450f-fb4d-50cb45f1f87d"
      },
      "source": [
        "learn.lr_find()"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SuggestedLRs(lr_min=7.585775892948732e-06, lr_steep=1.3182567499825382e-06)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4E4JaTlc-7GZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 1e-05"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RQc4ODU92vr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "be8d8787-1893-4880-fe6c-9e620bf69671"
      },
      "source": [
        "learn.fit_one_cycle(6, lr)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.873560</td>\n",
              "      <td>2.860932</td>\n",
              "      <td>0.089000</td>\n",
              "      <td>15:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.956807</td>\n",
              "      <td>1.998694</td>\n",
              "      <td>0.420000</td>\n",
              "      <td>15:32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.533745</td>\n",
              "      <td>1.407617</td>\n",
              "      <td>0.591500</td>\n",
              "      <td>15:27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.145570</td>\n",
              "      <td>1.297458</td>\n",
              "      <td>0.610000</td>\n",
              "      <td>15:40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.824155</td>\n",
              "      <td>1.118888</td>\n",
              "      <td>0.661000</td>\n",
              "      <td>15:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.784426</td>\n",
              "      <td>1.086315</td>\n",
              "      <td>0.679000</td>\n",
              "      <td>15:35</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3G5kAEM3QKWA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D6HoOLa37gP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.path = config.MODEL_PATH"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "km3IUP2OQTHY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.export('pretrained_xlmroberta.pkl')"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1DpFeKNPCn3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "6898833a-97f4-471f-a01e-34d012adf53c"
      },
      "source": [
        "learn = load_learner(config.MODEL_PATH/'pretrained_xlmroberta.pkl', cpu=False)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-4b352c484c77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m'pretrained_xlmroberta.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36mload_learner\u001b[0;34m(fname, cpu)\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;34m\"Load a `Learner` object in `fname`, optionally putting it on the `cpu`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m     \u001b[0mdistrib_barrier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcpu\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'to_fp32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_fp32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    591\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    771\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    727\u001b[0m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_torch_load_uninitialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mroot_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mroot_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mview_metadata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0mstorage_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mstorage_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_new\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;31m# We may need to call lazy init again if we are a forked child\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;31m# del _CudaBase.__new__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_CudaBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nc8P4abrRbah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.dls = dls_clas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yWA4iuVMPd0Q"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VF-y8ra2DJgj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a2a3906f-e8ea-478e-bc22-2f38b1be4268"
      },
      "source": [
        "test_df = pd.read_csv(config.TEST_FILE, sep='\\t').fillna(' ')\n",
        "len(test_df)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "937"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiyNqtIp4t4p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "6a5e524e-692e-45bf-f587-f49e35605fbc"
      },
      "source": [
        "test_items = TfmdLists(test_df, [attrgetter('text'), custom_tokenizer, Numericalize(vocab=trans2fastai_vocab), Add_Special_Cls])"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlA3LkGCKnjT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b7315c39-2a54-4247-9440-475445675e7e"
      },
      "source": [
        "# test_dl = test_items.dataloaders(bs=4, before_batch=[pad], seq_len=config.MAX_SEQ_LEN)"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Could not do one pass in your dataloader, there is something wrong in it\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaTRtRlIKUkb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "outputId": "b29990b7-1849-4c70-bd6d-a93b83f5f615"
      },
      "source": [
        "learn.model.eval()\n",
        "with torch.no_grad():\n",
        "    for ti in test_items:\n",
        "        out = learn.model(torch.cat((ti[None], tensor([0] * 5)[None]), dim=1).cuda())\n",
        "        print(out.shape)\n",
        "        break"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-c4685729ab86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mti\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_items\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mti\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg_Az7QT-WSX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0suycAPC8ggc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "37dcc91f-e707-4ab4-a4f2-f4b34bb7924e"
      },
      "source": [
        "test_items = tokenize_df(df=test_df, text_cols=['Title', 'Description'], tok_func=HFTokenizer, res_col_name='text')"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-dvsjHujqmO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_test_dl = learn.dls.test_dl(test_items=test_items)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPaTWT82bCvh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a6c04b95-bfbc-400a-f5b8-56583cc1a260"
      },
      "source": [
        "# preds, _, preds_raw = \n",
        "learn.get_preds(dl=_test_dl, with_decoded=False, with_input=True)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(self, i, b)\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m                                  \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'begin_batch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m                \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_pred'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-b10cd2c6b2c3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mh_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_extended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    407\u001b[0m             layer_outputs = layer_module(\n\u001b[0;32m--> 408\u001b[0;31m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    368\u001b[0m     ):\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0mself_attention_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    314\u001b[0m         self_outputs = self.self(\n\u001b[0;32m--> 315\u001b[0;31m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    216\u001b[0m     ):\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mmixed_query_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1611\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1612\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_INTERNAL_ERROR when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36m_do_epoch_validate\u001b[0;34m(self, ds_idx, dl)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m;\u001b[0m                                    \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'begin_validate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCancelValidException\u001b[0m\u001b[0;34m:\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_cancel_validate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36mall_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(self, i, b)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCancelBatchException\u001b[0m\u001b[0;34m:\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_cancel_batch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m                                             \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_batch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, event_name)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_one\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastcore/foundation.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, f, *args, **kwargs)\u001b[0m\n\u001b[1;32m    376\u001b[0m              else f.__getitem__)\n\u001b[0;32m--> 377\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastcore/foundation.py\u001b[0m in \u001b[0;36m_new\u001b[0;34m(self, items, *args, **kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_xtra\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastcore/foundation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_newchk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastcore/foundation.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, items, use_list, match, *rest)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0muse_list\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_list\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_listify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastcore/foundation.py\u001b[0m in \u001b[0;36m_listify\u001b[0;34m(o)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_is_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mis_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastcore/foundation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mfargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Arg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpargs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36m_call_one\u001b[0;34m(self, event_name)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msort_by_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msort_by_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/callback/core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, event_name)\u001b[0m\n\u001b[1;32m     23\u001b[0m                (self.run_valid and not getattr(self, 'training', False)))\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_run\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'after_fit'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m \u001b[0;31m#Reset self.run to True at each end of fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/callback/core.py\u001b[0m in \u001b[0;36mafter_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;34m\"Save predictions, targets and potentially losses\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_detach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mto_detach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_preds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/torch_core.py\u001b[0m in \u001b[0;36mto_detach\u001b[0;34m(b, cpu, gather)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcpu\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_inner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/torch_core.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(func, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mretain_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/torch_core.py\u001b[0m in \u001b[0;36m_inner\u001b[0;34m(x, cpu, gather)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_gather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcpu\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_inner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-24bd57cbc7d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# preds, _, preds_raw =\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_test_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_decoded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36mget_preds\u001b[0;34m(self, ds_idx, dl, with_input, with_decoded, with_loss, act, inner, reorder, **kwargs)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmgr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mctx_mgrs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmgr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_epoch\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minner\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_before_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_epoch\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minner\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_after_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mact\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'activation'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36m_do_epoch_validate\u001b[0;34m(self, ds_idx, dl)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCancelValidException\u001b[0m\u001b[0;34m:\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_cancel_validate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m                                             \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_validate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mlog_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbut\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cbs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, event_name)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mordered_cbs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msort_by_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_one\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastcore/foundation.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, f, *args, **kwargs)\u001b[0m\n\u001b[1;32m    375\u001b[0m              \u001b[0;32melse\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m              else f.__getitem__)\n\u001b[0;32m--> 377\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastcore/foundation.py\u001b[0m in \u001b[0;36m_new\u001b[0;34m(self, items, *args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_xtra\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastcore/foundation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_newchk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastcore/foundation.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, items, use_list, match, *rest)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mitems\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0muse_list\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_list\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_listify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_coll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastcore/foundation.py\u001b[0m in \u001b[0;36m_listify\u001b[0;34m(o)\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_is_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mis_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastcore/foundation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_Arg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mfargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Arg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpargs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36m_call_one\u001b[0;34m(self, event_name)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msort_by_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_bn_bias_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mbn_bias_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msort_by_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_bn_bias_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mbn_bias_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/callback/core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, event_name)\u001b[0m\n\u001b[1;32m     22\u001b[0m         _run = (event_name not in _inner_loop or (self.run_train and getattr(self, 'training', True)) or\n\u001b[1;32m     23\u001b[0m                (self.run_valid and not getattr(self, 'training', False)))\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_run\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'after_fit'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m \u001b[0;31m#Reset self.run to True at each end of fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/callback/core.py\u001b[0m in \u001b[0;36mafter_validate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;34m\"Concatenate all recorded tensors\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_input\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mdetuplify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_preds\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreds\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mdetuplify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_targs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetuplify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_loss\u001b[0m\u001b[0;34m:\u001b[0m      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mto_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/torch_core.py\u001b[0m in \u001b[0;36mto_concat\u001b[0;34m(xs, dim)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mto_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;34m\"Concat the element in `xs` (recursively if they are tuples/lists of tensors)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mto_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;31m#We may receives xs that are not concatenatable (inputs of a text classifier for instance),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENTSoS-JG4t8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "04d9ec0d-40cb-4186-f300-26d706041b27"
      },
      "source": [
        "preds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[9.9767e-01],\n",
              "        [2.4747e-06],\n",
              "        [2.0972e-06],\n",
              "        ...,\n",
              "        [1.0581e-05],\n",
              "        [9.9848e-01],\n",
              "        [8.9927e-01]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UldIvxAerum8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "56af17d5-0e6b-4769-fd33-563f2179734a"
      },
      "source": [
        "any(preds) == any(preds_raw)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_kL7MOpYADU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = sum(all_preds)/ len(all_preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIKU_6vuNR61",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "4ed6441d-816a-40fb-f860-f96a03df468a"
      },
      "source": [
        "preds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([8.8596e-01, 5.9015e-05, 1.9469e-03,  ..., 5.2246e-05, 8.8848e-01,\n",
              "        8.1959e-01])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OQI1iRdXtyTm",
        "colab": {}
      },
      "source": [
        "sample = pd.read_csv(data_path/'sub.csv')\n",
        "# sample.loc[:, 'label'] = preds.flatten()\n",
        "sample.loc[:, 'target'] = preds\n",
        "\n",
        "sample.to_csv(\"roberta-vaccine-submission.tsv\", index=False, sep='\\t')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
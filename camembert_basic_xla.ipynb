{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "camembert_basic_xla.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM40qQLLzysjdFtT63ehpCl"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojVNxYojvluc",
        "colab_type": "text"
      },
      "source": [
        "## CORE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ECpdOsxvpIL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install fastcore fastai2 transformers -q"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8n-epaRvstb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastcore.foundation import *\n",
        "from fastai2.text.all import *\n",
        "import transformers\n",
        "import pathlib"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRNfH41qvya5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@patch\n",
        "def ls(x: pathlib.Path):\n",
        "    return list(x.iterdir())"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiTyipOvcPQA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import os\n",
        "# from pathlib import Path\n",
        "from google.colab import drive"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nipZBIQ2amuD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_path(path):\n",
        "    if not os.path.isdir(path):\n",
        "        path.mkdir(parents=True, exist_ok=True)\n",
        "    return path"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SY8hz8XI_GDl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "colab_path = Path('/content')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jE3i8uUsdkvL",
        "colab_type": "text"
      },
      "source": [
        "handles all gdrive downloads for when running on cluster"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieIwxYONdo83",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "create_path(colab_path/'dataset');\n",
        "create_path(colab_path/'models');\n",
        "\n",
        "!git clone --quiet 'https://github.com/tezike/download_google_drive.git'\n",
        "os.chdir('download_google_drive')\n",
        "!python download_gdrive.py '10rH0nAxa7mWS289xIyRP-mOOowqiIolL' '../dataset/temp.tgz'\n",
        "shutil.rmtree('../download_google_drive')\n",
        "os.chdir('..')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQNK70EuxrRr",
        "colab_type": "text"
      },
      "source": [
        "## Colab_setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdKS3nNT0IKp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "0bbb1c2c-4015-4b4f-840d-de5c2145a755"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "root_dir = Path('/content/drive/My Drive')\n",
        "base_path = create_path(root_dir/'Rakuten')\n",
        "base_path"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('/content/drive/My Drive/Rakuten')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTjrkANjx9tM",
        "colab_type": "text"
      },
      "source": [
        "## download and untar data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMhQRUE0zfTR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -xzf $colab_path/'dataset/temp.tgz' # && tar -xzf ${colab_path/'lm-encoder-splits.tar.gz'} -C ${colab_path}"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNVdbQdYcYyv",
        "colab_type": "text"
      },
      "source": [
        "## FIN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKlgX2w5aXqo",
        "colab_type": "text"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saxAHHGZCWnf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Config():\n",
        "    def __init__(self):\n",
        "        self.MODEL_NAME = 'xlm-roberta-base'\n",
        "        self.LM_MODEL = transformers.XLMRobertaForMaskedLM.from_pretrained(self.MODEL_NAME)\n",
        "        self.CLAS_MODEL = transformers.XLMRobertaModel #.from_pretrained(MODEL_NAME)\n",
        "        self.TOKENIZER = transformers.XLMRobertaTokenizer.from_pretrained(\n",
        "                    pretrained_model_name_or_path=self.MODEL_NAME,\n",
        "                    do_lower_case=True,\n",
        "                    )\n",
        "        self.MODEL_CONFIG = transformers.XLMRobertaConfig.from_pretrained(self.MODEL_NAME)\n",
        "        self.COLAB_PATH = Path('/content')\n",
        "        self.BASE_PATH = base_path\n",
        "        self.DATA_PATH = create_path(base_path/'dataset')\n",
        "        self.MODEL_PATH = create_path(base_path/'models')\n",
        "        self.TEST_FILE = self.COLAB_PATH/'SIGIR-2020-EComDC-release/data/x_test_task1_phase1.tsv'\n",
        "        self.MAX_SEQ_LEN = 512\n",
        "        self.DEVICE = torch.device(f\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "config = Config()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCQNMKa1iP-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Config():\n",
        "    def __init__(self):\n",
        "        self.MODEL_NAME = 'roberta-base'\n",
        "        self.LM_MODEL = transformers.RobertaForMaskedLM.from_pretrained(self.MODEL_NAME)\n",
        "        self.CLAS_MODEL = transformers.RobertaForSequenceClassification #.from_pretrained(MODEL_NAME)\n",
        "        self.TOKENIZER = transformers.RobertaTokenizer.from_pretrained(\n",
        "                    pretrained_model_name_or_path=self.MODEL_NAME,\n",
        "                    do_lower_case=True,\n",
        "                    )\n",
        "        self.MODEL_CONFIG = transformers.RobertaConfig.from_pretrained(self.MODEL_NAME)\n",
        "        self.COLAB_PATH = Path('/content')\n",
        "        self.BASE_PATH = base_path\n",
        "        self.DATA_PATH = create_path(base_path/'dataset')\n",
        "        self.MODEL_PATH = create_path(base_path/'models')\n",
        "        self.TEST_FILE = self.COLAB_PATH/'SIGIR-2020-EComDC-release/data/x_test_task1_phase1.tsv'\n",
        "        self.MAX_SEQ_LEN = 512\n",
        "        self.DEVICE = torch.device(f\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "config_rob = Config()"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWPCguragmlm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# config.TOKENIZER.build_inputs_with_special_tokens(config.TOKENIZER.convert_tokens_to_ids(config.TOKENIZER.tokenize('he is a sheep', add_prefix_space=True)))"
      ],
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDro6neCfIzK",
        "colab_type": "text"
      },
      "source": [
        "## TOKENIZER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLAKbVsBe3c2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "e22cbd2c-f1fc-4cba-d453-3783f94bd20d"
      },
      "source": [
        "config.DATA_PATH.ls()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Path('/content/drive/My Drive/Rakuten/dataset/._SIGIR-2020-EComDC-release'),\n",
              " Path('/content/drive/My Drive/Rakuten/dataset/SIGIR-2020-EComDC-release'),\n",
              " Path('/content/drive/My Drive/Rakuten/dataset/temp.tgz'),\n",
              " Path('/content/drive/My Drive/Rakuten/dataset/rand_splits_10000_baseline.npy'),\n",
              " Path('/content/drive/My Drive/Rakuten/dataset/submission_baseline_10000_score_38.4.csv'),\n",
              " Path('/content/drive/My Drive/Rakuten/dataset/submission_baseline_10000_score_38.4.tsv'),\n",
              " Path('/content/drive/My Drive/Rakuten/dataset/rand_files_sample_10000.npy'),\n",
              " Path('/content/drive/My Drive/Rakuten/dataset/sample_df.csv'),\n",
              " Path('/content/drive/My Drive/Rakuten/dataset/df_all.csv')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Zn7-g_hjUdO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bef6e847-3c42-4e2c-dfed-75e6a23703c0"
      },
      "source": [
        "transformer_vocab = config.TOKENIZER.get_vocab()\n",
        "trans2fastai_vocab = [k for k, v in sorted(transformer_vocab.items(), key=lambda item: item[1])]\n",
        "len(trans2fastai_vocab)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "250002"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dX-mBCBrfLKb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HFTokenizer():\n",
        "    def __init__(self, tokenizer=config.TOKENIZER, seq_len=config.MAX_SEQ_LEN):\n",
        "        self.tok = tokenizer\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def tokenize(self, text):\n",
        "\n",
        "        tokens = self.tok.tokenize(text)\n",
        "\n",
        "        return tokens\n",
        "\n",
        "    def __call__(self, items:Str):\n",
        "        # ALways yeild the tokenized text before passing it to the Tokenizer Transform\n",
        "        tokenized = []\n",
        "        for text in items:\n",
        "            yield self.tokenize(text)[:self.seq_len-2]\n",
        "            # tokenized.append(self.tokenize(text)[:self.seq_len-2])\n",
        "        return tokenized"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sicOZTM8jNo3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Add_Special_Cls(Transform):\n",
        "    order = 7\n",
        "    def __init__(self, tokenizer=config.TOKENIZER):\n",
        "        self.tok = tokenizer\n",
        "\n",
        "    def encodes(self, o):\n",
        "        return TensorText(self.tok.build_inputs_with_special_tokens(list(o)))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRoFfKMFv3TN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@Tokenizer\n",
        "def decodes(self, o): return TitledStr(str(self.tokenizer.tok.convert_tokens_to_string(o)))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLsyn4UYj1LZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "custom_tokenizer = Tokenizer.from_df(text_cols=['Title', 'Description'], tok_func=HFTokenizer, rules=[fix_html], post_rules=[])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKB2UAc9HAIY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "outputId": "6c8737b0-2f84-475e-8af6-6f4e3a78e489"
      },
      "source": [
        "df_all = pd.read_csv(config.BASE_PATH/'dataset/df_all.csv'); df_all.sample(1)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Description</th>\n",
              "      <th>Image_id</th>\n",
              "      <th>Product_id</th>\n",
              "      <th>Prdtypecode</th>\n",
              "      <th>Prdlbl</th>\n",
              "      <th>image_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31150</th>\n",
              "      <td>Bebek Bébé En Peluche Hochets Poignée De Traction Jouer Jouets Lit Bébé Poussette Hanging Jeux Éducatifs 1388</td>\n",
              "      <td>Enfant en peluche hochets poignée de traction Jouer Jouets Lit bébé poussette Hanging Feature: 100% tout neuf et haute. Quantité: 1 Très doux et confortable au toucher Un grand jouet en peluche pour vos enfants grand cadeau pour l&amp;#39;anniversaire de mariage et bébé Taille: 11cmX7cm peut choisir: sous-marin fusée bateau de voiture Contenu: 1X Peluche animal bébé bébé enfants Clochettes hochets pour bébé Kid cadeau</td>\n",
              "      <td>1254358095</td>\n",
              "      <td>3861177097</td>\n",
              "      <td>1280</td>\n",
              "      <td>1280</td>\n",
              "      <td>/content/SIGIR-2020-EComDC-release/image/image_training/image_1254358095_product_3861177097.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                               Title  ...                                                                                       image_path\n",
              "31150  Bebek Bébé En Peluche Hochets Poignée De Traction Jouer Jouets Lit Bébé Poussette Hanging Jeux Éducatifs 1388  ...  /content/SIGIR-2020-EComDC-release/image/image_training/image_1254358095_product_3861177097.jpg\n",
              "\n",
              "[1 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQ_KjVy0MR_c",
        "colab_type": "text"
      },
      "source": [
        "# Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgDvkdC7XdmU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_input_chunk(samples, pad_idx=1, pad_first=True, seq_len=72):\n",
        "    \"Pad `samples` by adding padding by chunks of size `seq_len`\"\n",
        "    max_len = max([len(s[0]) for s in samples])\n",
        "    def _f(x):\n",
        "        l = max_len - x.shape[0]\n",
        "        pad_chunk = x.new_zeros((l//seq_len) * seq_len) + pad_idx\n",
        "        pad_res   = x.new_zeros(l % seq_len) + pad_idx\n",
        "        x1 = torch.cat([pad_chunk, x, pad_res]) if pad_first else torch.cat([x, pad_res, pad_chunk])\n",
        "        return retain_type(x1, x)\n",
        "    return [(_f(s[0]), *s[1:]) for s in samples]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoGDk7BRXc3b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pad = partial(pad_input_chunk, pad_idx=config.TOKENIZER.pad_token_id, pad_first=False, seq_len=config.MAX_SEQ_LEN)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2YX5NAiMUEj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfms = [attrgetter('text'), \n",
        "            custom_tokenizer, Numericalize(vocab=trans2fastai_vocab), \n",
        "            Add_Special_Cls]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WOi5d6FL2CB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "splits = RandomSplitter()(df_all)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4POr_fL2SoW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "b89a0f65-c239-4e16-91b7-02ec8b9f107e"
      },
      "source": [
        "dsets = Datasets(df_all, tfms=[tfms, [attrgetter('Prdlbl'), Categorize]], splits=splits, dl_type=SortedDL)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNE912a_3-To",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dls_clas = dsets.dataloaders(bs=4, val_bs=4, before_batch=[pad], seq_len=config.MAX_SEQ_LEN)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N49AB5Qa4Myk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 922
        },
        "outputId": "dfbd7074-cd0d-4ade-d5d1-393457f1f8e3"
      },
      "source": [
        "dls_clas.show_batch()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;s&gt; xxfld 1 décoration du foyer coussin trou noir stellaire taie d'oreiller jeter covers cc4440 xxfld 2 décoration du foyer coussin stellar trou noir taie coussin couvre point de vente de produits: décoration de la maison: throw taies d&amp;'oreiller sont perfert pour décorer votre chambre .suitable pour le salon chambre à coucher un canapé un canapé voiture siège sol banc bureau café partie ect. fermeture à glissière est caché et smoothly.putting votre insert dans puis de nouveaux coussins pourrait terminée. insert d&amp;'oreiller pourrait facilement être frappé légèrement ou enlevé vous pouvez laver taie d&amp;'oreiller en tout temps de sorte que votre oreiller jet pourrait toujours garder propre et belle. conseils de lavage: lavage en machine à froid séparément doucement cycle seulement dot non eau de javel sèche-linge ne pas repasser et il va tout nouveau look. le motif imprimé est disponible uniquement sur la face avant arrière sans impression grand</td>\n",
              "      <td>1920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;s&gt; xxfld 1 peinture décorative salle de bedroomliving tv murale décoration murale mureaux xxfld 2 peinture décorative salle de bedroomliving tv murale décoration murale mureaux caractéristiques: 100% tout neuf et de haute qualité. quantité: 1pc protection non toxique environnement imperméable matière: pvc motif: avion autocollant mural facile à appliquer supprimer déplacer et réutiliser sans laisser de dommage ou de résidus. la taille mesurée manuellement. la tolérance est de 1 cm. peut être appliqué sur toute surface sans poussière lisse sec comme porte en verre vitre carreaux de céramique dans la cuisine ou salle de bain lunettes appareils ménagers air conditionné et le corps de voiture nous faisons de notre meilleur spectacle du produit réel. mais s&amp;'il vous plaît comprendre la couleur encore peut-être un peu différent selon l&amp;'effet illustration et de l&amp;'écran. un sticker mural art mur beautiflu pour votre maison ou au bureau donnera à votre pièce un aspect</td>\n",
              "      <td>2060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;s&gt; xxfld 1 papier peint | fond illuminé | 300x231 | | xxfld 2 &lt;strong&gt;papier peint&lt;/strong&gt; intissé \"fond illuminé\" solide résistant à l&amp;'eau et aux rayures est à poser au mur. papier peint intissé \"fond illuminé\" représentant un motif inspiré sera une décoration particulière pour toutes les pièces. les papiers peints intissés sont posés au mur avec une colle speciale .celui-ci peut être posé dans chaque pièce une salle de bain et dans la cuisine. il se distingue par une surface demi terne et couvre les imperfections du mur. &lt;strong&gt;impression de la haute qualité&lt;/strong&gt; l&amp;'impression numérique de la résolution de 600dpi dans la technologie unique et les couleurs vives de papier peint intissé font remplir votre mur et agrandir votre intérieur. celui-ci forme une couche isolante et permet aux murs de respirer. l&amp;'impression résistante à l&amp;'eau est très durable. &lt;strong&gt;eco et en sécurité&lt;/strong&gt; en utilisant des matériaux fiables nos papiers</td>\n",
              "      <td>2060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;s&gt; xxfld 1 v-rally 4 - jeu en téléchargement xxfld 2 &lt;div&gt; &lt;p&gt;&lt;strong&gt;note :&lt;/strong&gt; un compte steam et une connexion internet sont nécessaires pour activer télécharger et utiliser ce produit.&lt;/p&gt; offre de précommande &lt;div&gt; &lt;p&gt;profitez d&amp;'un accès anticipé à la légendaire ford shelby gt500&lt;/p&gt; &lt;/div&gt; à propos du jeu &lt;p&gt;le retour d&amp;'une légende des jeux de course off-road ! vivez une expérience extrême en maîtrisant une simulation exigeante. relevez les défis du rallye du rallycross du drift du buggy ou de l&amp;'hill climb et partez pour un voyage spectaculaire sur tous les continents.&lt;/p&gt; &lt;p&gt;dominez des routes dangereuses des conditions et des environnements hostiles recherchez toujours plus de vitesse et laissez l&amp;'adrénaline booster vos réflexes. au volant des bolides off-road les plus mythiques de chaque catégorie affrontez les tracés les plus difficiles dans de fabuleux décors.&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;strong&gt;rallye :&lt;/strong&gt; du kenya à sequoia park dominez les tracés les plus difficiles dans des</td>\n",
              "      <td>2905</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnBN29Xr5bfi",
        "colab_type": "text"
      },
      "source": [
        "## For clas learner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiDJTDVHP49v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def roberta_cls_splitter(m):\n",
        "    \"Split the classifier head from the backbone\"\n",
        "    groups = [nn.Sequential(m.model.embeddings,\n",
        "                  m.model.encoder.layer[0],\n",
        "                  m.model.encoder.layer[1],\n",
        "                  m.model.encoder.layer[2],\n",
        "                  m.model.encoder.layer[3],\n",
        "                  m.model.encoder.layer[4],\n",
        "                  m.model.encoder.layer[5],\n",
        "                  m.model.encoder.layer[6],\n",
        "                  m.model.encoder.layer[7],\n",
        "                  m.model.encoder.layer[8],\n",
        "                  m.model.encoder.layer[9],\n",
        "                  m.model.encoder.layer[10],\n",
        "                  m.model.encoder.layer[11],\n",
        "                  m.model.pooler)]\n",
        "    groups = L(groups + [m.lin])\n",
        "    return groups.map(params)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0eEXX7ZdD-B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Clas_Model(nn.Module):\n",
        "    def __init__(self, pretrained=True, num_classes=dls_clas.c, load_encoder=True):\n",
        "        super(Clas_Model, self).__init__()\n",
        "        if pretrained:\n",
        "            self.model = config.CLAS_MODEL(config.MODEL_CONFIG)\n",
        "\n",
        "        else: \n",
        "            self.model = config.CLAS_MODEL.from_pretrained(config.MODEL_NAME)\n",
        "\n",
        "        if load_encoder: self.load_lm_encoder(self.model, config.MODEL_PATH/'roberta_pretrained_lm.pkl')\n",
        "        \n",
        "        self.drop = nn.Dropout(0.2)\n",
        "\n",
        "        self.lin = nn.Linear(768*2, num_classes)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        attention_mask =  (x!=config.TOKENIZER.pad_token_id).type(x.type())\n",
        "\n",
        "        h_0, _ = self.model(x, attention_mask=attention_mask)\n",
        "        \n",
        "        mean_pool = torch.mean(h_0, 1)\n",
        "\n",
        "        max_pool = torch.max(h_0, 1)[0]\n",
        "\n",
        "        out = torch.cat([mean_pool, max_pool], 1)\n",
        "\n",
        "        out = self.lin(self.drop(out))\n",
        "\n",
        "        return out\n",
        "\n",
        "    def load_lm_encoder(self,clas_model, lm_path=None):\n",
        "        clas_model_dict = clas_model.state_dict()\n",
        "        if lm_path is not None:\n",
        "            lm_model_dict = torch.load(lm_path).model.state_dict()\n",
        "            needed_dict = {k[6:]:v for k, v in lm_model_dict.items() if str(k)[6:] in clas_model_dict.keys()}\n",
        "            clas_model_dict.update(needed_dict)\n",
        "        clas_model.load_state_dict(clas_model_dict)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAm361lhwYt9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Clas_Model(pretrained=True, load_encoder=False)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQEFWD3J71SF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt_func = partial(Adam, decoupled_wd=True) #AdamW\n",
        "learn = Learner(dls_clas, model, metrics=accuracy, drop_mult=0., loss_func=CrossEntropyLossFlat(), opt_func=opt_func)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUcr8EQI9MSk",
        "colab_type": "text"
      },
      "source": [
        "Make only the last layer trainable then gradually unfreeze the rest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCPj72RtDDKL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# learn.freeze()"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMhoC53U8mEk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c786b10b-9399-4e68-97eb-8258cb00fd42"
      },
      "source": [
        "learn.summary()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Clas_Model (Input shape: ['4 x 87'])\n",
              "================================================================\n",
              "Layer (type)         Output Shape         Param #    Trainable \n",
              "================================================================\n",
              "Embedding            4 x 87 x 768         192,001,536 True      \n",
              "________________________________________________________________\n",
              "Embedding            4 x 87 x 768         394,752    True      \n",
              "________________________________________________________________\n",
              "Embedding            4 x 87 x 768         768        True      \n",
              "________________________________________________________________\n",
              "LayerNorm            4 x 87 x 768         1,536      True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 87 x 768         0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 12 x 87 x 87     0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "LayerNorm            4 x 87 x 768         1,536      True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 87 x 768         0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 3072        2,362,368  True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         2,360,064  True      \n",
              "________________________________________________________________\n",
              "LayerNorm            4 x 87 x 768         1,536      True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 87 x 768         0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 12 x 87 x 87     0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "LayerNorm            4 x 87 x 768         1,536      True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 87 x 768         0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 3072        2,362,368  True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         2,360,064  True      \n",
              "________________________________________________________________\n",
              "LayerNorm            4 x 87 x 768         1,536      True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 87 x 768         0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 12 x 87 x 87     0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "LayerNorm            4 x 87 x 768         1,536      True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 87 x 768         0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 3072        2,362,368  True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         2,360,064  True      \n",
              "________________________________________________________________\n",
              "LayerNorm            4 x 87 x 768         1,536      True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 87 x 768         0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 12 x 87 x 87     0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "LayerNorm            4 x 87 x 768         1,536      True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 87 x 768         0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 3072        2,362,368  True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         2,360,064  True      \n",
              "________________________________________________________________\n",
              "LayerNorm            4 x 87 x 768         1,536      True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 87 x 768         0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 12 x 87 x 87     0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "LayerNorm            4 x 87 x 768         1,536      True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 87 x 768         0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 3072        2,362,368  True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         2,360,064  True      \n",
              "________________________________________________________________\n",
              "LayerNorm            4 x 87 x 768         1,536      True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 87 x 768         0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 12 x 87 x 87     0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "LayerNorm            4 x 87 x 768         1,536      True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 87 x 768         0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 3072        2,362,368  True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         2,360,064  True      \n",
              "________________________________________________________________\n",
              "LayerNorm            4 x 87 x 768         1,536      True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 87 x 768         0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 12 x 87 x 87     0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "LayerNorm            4 x 87 x 768         1,536      True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 87 x 768         0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 3072        2,362,368  True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         2,360,064  True      \n",
              "________________________________________________________________\n",
              "LayerNorm            4 x 87 x 768         1,536      True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 87 x 768         0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 12 x 87 x 87     0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "LayerNorm            4 x 87 x 768         1,536      True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 87 x 768         0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 3072        2,362,368  True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         2,360,064  True      \n",
              "________________________________________________________________\n",
              "LayerNorm            4 x 87 x 768         1,536      True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 87 x 768         0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 12 x 87 x 87     0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "LayerNorm            4 x 87 x 768         1,536      True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 87 x 768         0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 3072        2,362,368  True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         2,360,064  True      \n",
              "________________________________________________________________\n",
              "LayerNorm            4 x 87 x 768         1,536      True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 87 x 768         0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 12 x 87 x 87     0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "LayerNorm            4 x 87 x 768         1,536      True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 87 x 768         0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 3072        2,362,368  True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         2,360,064  True      \n",
              "________________________________________________________________\n",
              "LayerNorm            4 x 87 x 768         1,536      True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 87 x 768         0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 12 x 87 x 87     0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "LayerNorm            4 x 87 x 768         1,536      True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 87 x 768         0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 3072        2,362,368  True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         2,360,064  True      \n",
              "________________________________________________________________\n",
              "LayerNorm            4 x 87 x 768         1,536      True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 87 x 768         0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 12 x 87 x 87     0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         590,592    True      \n",
              "________________________________________________________________\n",
              "LayerNorm            4 x 87 x 768         1,536      True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 87 x 768         0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 3072        2,362,368  True      \n",
              "________________________________________________________________\n",
              "Linear               4 x 87 x 768         2,360,064  True      \n",
              "________________________________________________________________\n",
              "LayerNorm            4 x 87 x 768         1,536      True      \n",
              "________________________________________________________________\n",
              "Dropout              4 x 87 x 768         0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 768              590,592    True      \n",
              "________________________________________________________________\n",
              "Tanh                 4 x 768              0          False     \n",
              "________________________________________________________________\n",
              "Dropout              4 x 1536             0          False     \n",
              "________________________________________________________________\n",
              "Linear               4 x 27               41,499     True      \n",
              "________________________________________________________________\n",
              "\n",
              "Total params: 278,085,147\n",
              "Total trainable params: 278,085,147\n",
              "Total non-trainable params: 0\n",
              "\n",
              "Optimizer used: functools.partial(<function Adam at 0x7fe06187bbf8>, decoupled_wd=True)\n",
              "Loss function: FlattenedLoss of CrossEntropyLoss()\n",
              "\n",
              "Callbacks:\n",
              "  - TrainEvalCallback\n",
              "  - Recorder\n",
              "  - ProgressCallback"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRaD3d_kHyYo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a492d282-e17b-4201-f280-9dcde98ff9b0"
      },
      "source": [
        "import gc; \n",
        "gc.collect()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "792"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "At5Cdg037aUQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "6f220587-0896-450f-fb4d-50cb45f1f87d"
      },
      "source": [
        "learn.lr_find()"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SuggestedLRs(lr_min=7.585775892948732e-06, lr_steep=1.3182567499825382e-06)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4E4JaTlc-7GZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 1e-05"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RQc4ODU92vr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "be8d8787-1893-4880-fe6c-9e620bf69671"
      },
      "source": [
        "learn.fit_one_cycle(6, lr)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.873560</td>\n",
              "      <td>2.860932</td>\n",
              "      <td>0.089000</td>\n",
              "      <td>15:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.956807</td>\n",
              "      <td>1.998694</td>\n",
              "      <td>0.420000</td>\n",
              "      <td>15:32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.533745</td>\n",
              "      <td>1.407617</td>\n",
              "      <td>0.591500</td>\n",
              "      <td>15:27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.145570</td>\n",
              "      <td>1.297458</td>\n",
              "      <td>0.610000</td>\n",
              "      <td>15:40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.824155</td>\n",
              "      <td>1.118888</td>\n",
              "      <td>0.661000</td>\n",
              "      <td>15:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.784426</td>\n",
              "      <td>1.086315</td>\n",
              "      <td>0.679000</td>\n",
              "      <td>15:35</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3G5kAEM3QKWA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D6HoOLa37gP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.path = config.MODEL_PATH"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "km3IUP2OQTHY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.export('pretrained_xlmroberta.pkl')"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1DpFeKNPCn3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "6898833a-97f4-471f-a01e-34d012adf53c"
      },
      "source": [
        "learn = load_learner(config.MODEL_PATH/'pretrained_xlmroberta.pkl', cpu=False)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-4b352c484c77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m'pretrained_xlmroberta.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36mload_learner\u001b[0;34m(fname, cpu)\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;34m\"Load a `Learner` object in `fname`, optionally putting it on the `cpu`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m     \u001b[0mdistrib_barrier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcpu\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'to_fp32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_fp32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    591\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    771\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    727\u001b[0m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_torch_load_uninitialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mroot_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mroot_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mview_metadata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0mstorage_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mstorage_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_new\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;31m# We may need to call lazy init again if we are a forked child\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;31m# del _CudaBase.__new__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_CudaBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nc8P4abrRbah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.dls = dls_clas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yWA4iuVMPd0Q"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VF-y8ra2DJgj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a2a3906f-e8ea-478e-bc22-2f38b1be4268"
      },
      "source": [
        "test_df = pd.read_csv(config.TEST_FILE, sep='\\t').fillna(' ')\n",
        "len(test_df)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "937"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiyNqtIp4t4p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "6a5e524e-692e-45bf-f587-f49e35605fbc"
      },
      "source": [
        "test_items = TfmdLists(test_df, [attrgetter('text'), custom_tokenizer, Numericalize(vocab=trans2fastai_vocab), Add_Special_Cls])"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlA3LkGCKnjT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b7315c39-2a54-4247-9440-475445675e7e"
      },
      "source": [
        "# test_dl = test_items.dataloaders(bs=4, before_batch=[pad], seq_len=config.MAX_SEQ_LEN)"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Could not do one pass in your dataloader, there is something wrong in it\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaTRtRlIKUkb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "outputId": "b29990b7-1849-4c70-bd6d-a93b83f5f615"
      },
      "source": [
        "learn.model.eval()\n",
        "with torch.no_grad():\n",
        "    for ti in test_items:\n",
        "        out = learn.model(torch.cat((ti[None], tensor([0] * 5)[None]), dim=1).cuda())\n",
        "        print(out.shape)\n",
        "        break"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-c4685729ab86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mti\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_items\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mti\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg_Az7QT-WSX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0suycAPC8ggc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "37dcc91f-e707-4ab4-a4f2-f4b34bb7924e"
      },
      "source": [
        "test_items = tokenize_df(df=test_df, text_cols=['Title', 'Description'], tok_func=HFTokenizer, res_col_name='text')"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-dvsjHujqmO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_test_dl = learn.dls.test_dl(test_items=test_items)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPaTWT82bCvh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a6c04b95-bfbc-400a-f5b8-56583cc1a260"
      },
      "source": [
        "# preds, _, preds_raw = \n",
        "learn.get_preds(dl=_test_dl, with_decoded=False, with_input=True)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(self, i, b)\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m                                  \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'begin_batch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m                \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_pred'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-b10cd2c6b2c3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mh_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_extended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    407\u001b[0m             layer_outputs = layer_module(\n\u001b[0;32m--> 408\u001b[0;31m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    368\u001b[0m     ):\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0mself_attention_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    314\u001b[0m         self_outputs = self.self(\n\u001b[0;32m--> 315\u001b[0;31m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    216\u001b[0m     ):\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mmixed_query_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1611\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1612\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_INTERNAL_ERROR when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36m_do_epoch_validate\u001b[0;34m(self, ds_idx, dl)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m;\u001b[0m                                    \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'begin_validate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCancelValidException\u001b[0m\u001b[0;34m:\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_cancel_validate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36mall_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(self, i, b)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCancelBatchException\u001b[0m\u001b[0;34m:\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_cancel_batch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m                                             \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_batch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, event_name)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_one\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastcore/foundation.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, f, *args, **kwargs)\u001b[0m\n\u001b[1;32m    376\u001b[0m              else f.__getitem__)\n\u001b[0;32m--> 377\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastcore/foundation.py\u001b[0m in \u001b[0;36m_new\u001b[0;34m(self, items, *args, **kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_xtra\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastcore/foundation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_newchk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastcore/foundation.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, items, use_list, match, *rest)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0muse_list\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_list\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_listify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastcore/foundation.py\u001b[0m in \u001b[0;36m_listify\u001b[0;34m(o)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_is_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mis_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastcore/foundation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mfargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Arg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpargs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36m_call_one\u001b[0;34m(self, event_name)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msort_by_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msort_by_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/callback/core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, event_name)\u001b[0m\n\u001b[1;32m     23\u001b[0m                (self.run_valid and not getattr(self, 'training', False)))\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_run\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'after_fit'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m \u001b[0;31m#Reset self.run to True at each end of fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/callback/core.py\u001b[0m in \u001b[0;36mafter_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;34m\"Save predictions, targets and potentially losses\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_detach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mto_detach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_preds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/torch_core.py\u001b[0m in \u001b[0;36mto_detach\u001b[0;34m(b, cpu, gather)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcpu\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_inner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/torch_core.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(func, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mretain_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/torch_core.py\u001b[0m in \u001b[0;36m_inner\u001b[0;34m(x, cpu, gather)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_gather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcpu\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_inner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-24bd57cbc7d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# preds, _, preds_raw =\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_test_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_decoded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36mget_preds\u001b[0;34m(self, ds_idx, dl, with_input, with_decoded, with_loss, act, inner, reorder, **kwargs)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmgr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mctx_mgrs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmgr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_epoch\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minner\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_before_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_epoch\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minner\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_after_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mact\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'activation'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36m_do_epoch_validate\u001b[0;34m(self, ds_idx, dl)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCancelValidException\u001b[0m\u001b[0;34m:\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_cancel_validate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m                                             \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_validate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mlog_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbut\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cbs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, event_name)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mordered_cbs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msort_by_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_one\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastcore/foundation.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, f, *args, **kwargs)\u001b[0m\n\u001b[1;32m    375\u001b[0m              \u001b[0;32melse\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m              else f.__getitem__)\n\u001b[0;32m--> 377\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastcore/foundation.py\u001b[0m in \u001b[0;36m_new\u001b[0;34m(self, items, *args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_xtra\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastcore/foundation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_newchk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastcore/foundation.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, items, use_list, match, *rest)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mitems\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0muse_list\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_list\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_listify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_coll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastcore/foundation.py\u001b[0m in \u001b[0;36m_listify\u001b[0;34m(o)\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_is_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mis_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastcore/foundation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_Arg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mfargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Arg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpargs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36m_call_one\u001b[0;34m(self, event_name)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msort_by_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_bn_bias_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mbn_bias_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msort_by_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_bn_bias_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mbn_bias_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/callback/core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, event_name)\u001b[0m\n\u001b[1;32m     22\u001b[0m         _run = (event_name not in _inner_loop or (self.run_train and getattr(self, 'training', True)) or\n\u001b[1;32m     23\u001b[0m                (self.run_valid and not getattr(self, 'training', False)))\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_run\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'after_fit'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m \u001b[0;31m#Reset self.run to True at each end of fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/callback/core.py\u001b[0m in \u001b[0;36mafter_validate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;34m\"Concatenate all recorded tensors\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_input\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mdetuplify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_preds\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreds\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mdetuplify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_targs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetuplify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_loss\u001b[0m\u001b[0;34m:\u001b[0m      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mto_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/torch_core.py\u001b[0m in \u001b[0;36mto_concat\u001b[0;34m(xs, dim)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mto_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;34m\"Concat the element in `xs` (recursively if they are tuples/lists of tensors)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mto_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;31m#We may receives xs that are not concatenatable (inputs of a text classifier for instance),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENTSoS-JG4t8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "04d9ec0d-40cb-4186-f300-26d706041b27"
      },
      "source": [
        "preds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[9.9767e-01],\n",
              "        [2.4747e-06],\n",
              "        [2.0972e-06],\n",
              "        ...,\n",
              "        [1.0581e-05],\n",
              "        [9.9848e-01],\n",
              "        [8.9927e-01]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UldIvxAerum8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "56af17d5-0e6b-4769-fd33-563f2179734a"
      },
      "source": [
        "any(preds) == any(preds_raw)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_kL7MOpYADU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = sum(all_preds)/ len(all_preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIKU_6vuNR61",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "4ed6441d-816a-40fb-f860-f96a03df468a"
      },
      "source": [
        "preds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([8.8596e-01, 5.9015e-05, 1.9469e-03,  ..., 5.2246e-05, 8.8848e-01,\n",
              "        8.1959e-01])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OQI1iRdXtyTm",
        "colab": {}
      },
      "source": [
        "sample = pd.read_csv(data_path/'sub.csv')\n",
        "# sample.loc[:, 'label'] = preds.flatten()\n",
        "sample.loc[:, 'target'] = preds\n",
        "\n",
        "sample.to_csv(\"roberta-vaccine-submission.tsv\", index=False, sep='\\t')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}